{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards a Scientific Workflow Description: a yt Project Prototype for Interdisciplinary Analysis\n",
    "\n",
    "### NCSA & iSchool at University of Illinois, University College London\n",
    "- [yt-project.org](http://yt-project.org/)\n",
    "- [data-exp-lab.github.io](https://data-exp-lab.github.io/)\n",
    "- [github.com/yt-project](https://github.com/yt-project/yt/)\n",
    "- [github.com/data-exp-lab/analysis_schema](https://github.com/data-exp-lab/analysis_schema)\n",
    "\n",
    "#### Authors: Sam Walkow, Dr. Chris Havlin, Dr. Matthew Turk, Corentin Cadiou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [The Learning Cliff: Computational Workflows](#first-bullet)\n",
    "* [Describing Scientific Analysis and Visualization](#second-bullet)\n",
    "* [What is yt?](#third-bullet)\n",
    "* [Using JSON as an Interface](#fourth-bullet)\n",
    "* [The Analysis Schema](#fifth-bullet)\n",
    "* [Connecting Existing Software to Declarative Description](#sixth-bullet)\n",
    "* [Supporting Workflows and Software](#seventh-bullet)\n",
    "* [Future Work](#eighth-bullet)\n",
    "* [About the Authors](#nineth-bullet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Learning Cliff: Computational Workflows<a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "Working with scientific data and open source software requires understanding a myriad of tools and best practices. Analysis and visualization using python and open source relies on paradigms like imperative programming and for loops to write code and nuances in syntax like dot notation. After that, there's learning the internal functionality of individual packages, which are often domain specific. \n",
    "\n",
    "Interdisciplinary work provides an extra barrier, as new ways of thinking and new tools are added to the work load, butting heads with the domain focused tools available. While discovery and reconfiguration of software tools can be an intersection of creativity and innovation, too often learning curves get in the way and slow research down, or cause the wheel to be reinvented over and over again in each domain. \n",
    "\n",
    "**Scientific workflow description** provides an alternative to the cognitive overhead of learning a new software package and use of imperative programming paradigms often used with python. We aim to unite the core aspects of interdisciplinary computational work using common natural science mental models while removing inherent domain-specific workflow and computing language barriers, creating an accessible scientific query environment. **This description is encoded in a JSON schema, accessed by the user through a configuration file, and run using python modules that attach the configuration file to the code which produces output.** \n",
    "\n",
    "In this case, 'the code' is [yt](http://yt-project.org/), an open source python library designed for scientific analysis and visualization of volumetric data from the physical sciences. We use yt, an computational astrophyics tool, to demonstrate how a domain specific software can operate within a descriptive framework. **Future work will include support for multiple python libaries across several domains.** \n",
    "\n",
    "Check out our previous work on understanding user mental models in yt here: https://samwalkow.github.io/2020-scipy-poster-domainstories/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Scientific Analysis and Visualization <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "    \n",
    "</div>\n",
    "    \n",
    "|Scientific Description Tool: Analysis Schema Workflow||\n",
    "| - |- |\n",
    "|![](images/AnalysisSchemaWorkflowLarge.png)| What does it mean to *describe* a workflow? **We have developed a scientific workflow description prototype, which is divided into three different pieces - the JSON schema, a browser interface for user interaction, and a render-engine that will execute the code**. Using a configuration file which will live in the broswer, users can select actions and add appropriate data for those actions which are controled by the JSON schema. Users can then submit this file to the rendering engine, creating output for their work. <br><br>This creates a flexible, language-agnostic, and structured way for users to explore, analysis and visualize natural science data. It weaves human and language together, in a way that fits with how both human and machine *think* about the data and the program. Our work is currently supporting yt, but the schema could be extended to other python libraries. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is yt?<a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "\n",
    "yt (https://yt-project.org/) is an open source python library designed for scientific analysis and visualization of volumetric data from the physical sciences. **The analysis schema is designed to operate on top of yt's existing functionalities, to provide intuitive and flexible access to yt operations.**\n",
    "\n",
    "Here's some yt examples:\n",
    "\n",
    "    Supernova Ignition Simulation\n",
    "    https://arxiv.org/abs/1807.07579\n",
    "    (Evan O’Connor and Sean Couch, MSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/supernova.png\" align=\"left\" width=\"500\"/>\n",
    "\n",
    "    \n",
    "<img src=\"images/weatherradar.png\" align=\"right\" width=\"500\"/>\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                         Predicted Weather Radar from Tornadogenesis Simulation\n",
    "                                                                                           Leigh Orf (University of Wisconsin),\n",
    "                                                                                                         Image Credit: NCSA AVL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using JSON as an Interface<a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|||\n",
    "|-|-|\n",
    "|<img src=\"images/ytSlicePlotJSONEntry.gif\" align=\"left\" width=\"1800\"/>|JSON as an interface also user's to access properties defined in the JSON schema, and add data that conforms to the schema's specifications, which in turn are submitted to the code behind the interface. **User's only need to understand JSON notation to use the code, or in this case yt. They don't need to know python or yt at all to use those tools in their analysis.** They can simply describe what they want the code to do in the JSON configuration file, and an output is returned.<br><br>**The file is used as its own validation, as users objects that make up the workflow are validated against a JSON schema, either at runtime or (in certain code editors) in real time**. Workflows can be unique to the user but conform to a broad, domain specification, which makes work in the analysis schema ease to create and reproduce.|   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Analysis Schema<a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ytSchemaTitle.png\" align=\"left\" width=\"400\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The analysis schema design provides a structured grammar from which users can describe and tell the story of their data analysis. It's meant to connect with the users understanding of the data, while accessing the code it needs to run the analysis. **The schema has been developed to be flexible so users are free to complete operations in any order, while working in a structured schema which ensures the input to the JSON interface is valid and can be run in code**. This helps eliminate syntax issues, code run out of order issues, and lowers the barrier to usage.\n",
    "\n",
    "<br>\n",
    "\n",
    "While the description are separate from yt, the mental model behind the data selection, transformation, and logic remain connected to yt. We change how users can access those operations, but not how yt handles the data it receives. In this way, users are learning how yt thinks and understands data input, while using description and their domain knowledge to reasoon with the data and the returned output.\n",
    "\n",
    "<br>\n",
    "\n",
    "**By providing an additional layer between the user and the imperative code, the goal of the analysis schema is not to further separate the user from the software, but to bring them closer to together by improving the communication and shared work between human and machine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Existing Software to Declarative Description <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "\n",
    "How does the description reach and run the software? The core pieces that the analysis schema functions using data classes, type hinting, and schema models. Analysis Schema also relies on !(Pydantic)[https://github.com/samuelcolvin/pydantic/] to produce the models. **The schema is generated from yt data classes and type annotations, which is then accessed by users to guide and structure their analysis in the JSON interface.** \n",
    "\n",
    "Pydantic is the vehicle that converts yt code into a model, which is then saved as a JSON schema that can be reference by the user. Data classes with type hinting allow pydantic to create the building blocks\n",
    " \n",
    "Below is the Analysis Schema workflow, where the `Dataset` dataclass is highlighted through the diagram:\n",
    "\n",
    "<img src=\"images/AnalysisSchemaDiagram.png\" align=\"left\" width=\"1200\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Workflows and Software<a class=\"anchor\" id=\"seventh-bullet\"></a>\n",
    "\n",
    "**The Analysis Schema is designed to make scientific software easier to use, easier to reproduce, and to create a foundational for a structured, analysis grammar.** Supporting individual workflows is the main goal of the analysis - and so we have developed multiple ways to use the schema: in Jupyter, in the command line, and in the browser.\n",
    "\n",
    "#### Working in Jupyter:\n",
    "\n",
    "This example is run using VSCode in Jupyter mode, where the output of the user's JSON instructions are displayed in the Jupyter server on the right hand side:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"middle\"><video controls src=\"images/AnalysisSchemaJupyter.mov\" align=\"center\" height=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working in the command line:\n",
    "\n",
    "Users can also submit the configuration file through the command line and produce output as image files. \n",
    "\n",
    "This example is also run in VSCode, but the file below is submitted through the command line and the output is written to a file instead:\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"middle\"> <video controls src=\"images/AnalysisSchemaCL.mov\" height=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browsed-based Analysis and Visualization\n",
    "\n",
    "In addition to Jupyter and command line workflows, we are also working towards a browser environment that allows to use the Analysis Schema without downloading any software. Our goal to remove hardware barriers to working with open source scientific software: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"middle\"><video controls src=\"images/schema_browser.mp4\" height=\"550\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work<a class=\"anchor\" id=\"eighth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beyond yt\n",
    "\n",
    "Open source scientific software foster innovation and supports a surge of new tools, which does introduce a sustainability problem for users. It's hard to keep up with new developments and learn new tools. The Analysis Schema is designed to address this problem - any python module can be added to the underlying model. This allows for any packages to be accessed and run in the JSON interface. So users can use JSON sytanx to run any scientific python code.\n",
    "\n",
    "Here's an example where [napari](https://napari.org/) is access through the JSON interface using VSCode and a Jupyter notebook:\n",
    "\n",
    "<div align=\"middle\"><video controls src=\"images/schema_napari.mp4\" width=\"800\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beyond Astrophysics\n",
    "\n",
    "Historically yt was developed for computational astrophysics, and it is our goal to expand yt beyond it's original domain but implementing a domain contexts system. Adding a way for the Analysis Schema to detect and adjust the schema according to the domain the user is working will just users more computational power to answer research questions. \n",
    "\n",
    "In the future, we are aiming to expand yt's capabilities to support: \n",
    "\n",
    "- __Geophysics__\n",
    "- __Neuroimaging__\n",
    "- __Weather__ \n",
    "- __Climate__\n",
    "- __Oceanography__\n",
    "\n",
    "**Common elements and operations are often used across natural science domains** and we aim to identify and encode those operations into the analysis schema to make yt's visualization and analysis functionality more accessible. \n",
    "\n",
    "Operations of analysis and visualization are often reused across domains including:\n",
    "- Loading and registering data into a coordinate system\n",
    "- Methods of aggregation\n",
    "- Methods of transformation\n",
    "- Methods of plotting\n",
    "\n",
    "**Once we understand how users from other domains understand and process data, we can add logic to the schema that allow for the language and how yt handles the data to better match what users expect.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out some geoscience visualization and anlaysis with yt:\n",
    "\n",
    "Mantle convection in a spherical shell calculated with [ASPECT](https://geodynamics.org/cig/software/aspect/). Temperature field overlaid with velocity vectors (black) and adaptively refined mesh (white), visualized with the experimental [yt-aspect frontend](https://github.com/yt-project/yt/pull/3109):\n",
    "\n",
    "<img src=\"images/ytAspect.png\" align=\"left\" width=\"650\"/>\n",
    "\n",
    "Additional geoscience visualizations at https://github.com/chrishavlin/AGU2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Authors<a class=\"anchor\" id=\"nineth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sam Walkow, Informatics PhD Student at the University of Illinois\n",
    "\n",
    "\n",
    "#### Contact:\n",
    "- [@samwalkow](https://twitter.com/SamWalkow)\n",
    "- swalkow2@illinois.edu\n",
    "\n",
    "|||\n",
    "| - |- |\n",
    "|<img src=\"images/swalkow_dec2020.jpg\" align=\"left\" width=\"250\"/>| Sam Walkow is a PhD student in Informatics interested in open source software sustainability, culture and data visualization. She's investigating these issues by looking at the intersection of human and computer workflows, problem solving and data conception and representation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chris Havlin, , Research Scientist in School of Information Sciences at the University of Illinois\n",
    "\n",
    "\n",
    "\n",
    "#### Contact:\n",
    "- [@s_i_r_h_c](https://twitter.com/s_i_r_h_c)\n",
    "- chavlin@illinois.edu \n",
    "- [chrishavlin.github.io](https://chrishavlin.github.io/)\n",
    "\n",
    "|||\n",
    "| - |- |\n",
    "|<img src=\"images/chavlin.jpg\" align=\"left\" width=\"250\"/>| Chris Havlin is a research scientist in the Data Exploration Lab at the School of Information Sciences at the University of Illinois. His research focuses on cross-domain data visualization and analysis in the physical sciences.| Chris Havlin is a research scientist in the Data Exploration Lab at the School of Information Sciences at the University of Illinois. His research focuses on cross-domain data visualization and analysis in the physical sciences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matthew Turk, Assistant Professor in School of Information Sciences at the University of Illinois\n",
    "\n",
    "Matthew Turk is an assistant professor in the School of Information Sciences and also holds an appointment with the Department of Astronomy in the College of Liberal Arts and Sciences. His research is focused on how individuals interact with data and how that data is processed and understood.\n",
    "\n",
    "At the University of Illinois, he leads the Data Exploration Lab and teaches in Data Visualization, Data Storytelling, and Computational Astrophysics.\n",
    "\n",
    "\n",
    "#### Contact:\n",
    "\n",
    "[Matthew Turk dot github dot io](https://matthewturk.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corentin Cadiou\n",
    "\n",
    "#### Contact:\n",
    "\n",
    "|||\n",
    "| - |- |\n",
    "|<img src=\"images/ccadiou.jpg\" align=\"left\" width=\"250\"/>| Corentin Cadiou is a postdoctoral researcher at the department of Physics and Astrophysics at University College London. His research focuses on simulating the formation of galaxies in the Universe. To that end, he is interested in exploring novel approaches to data analysis and data processing of numerical simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "We would like to thank major yt contributors including Nathan Goldbaum, and the larger yt community for their sustained effort.\n",
    "\n",
    "We would also like to thank the following entities for their support:\n",
    "\n",
    "- The Gordon and Betty Moore Foundation’s Data-Driven Discovery Initiative through Grant GBMF4561.\n",
    "- The National Science Foundation under Grants OAC-1663914 and ACI-1535651\n",
    "- NumFOCUS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css2?family=Hind+Siliguri&display=swap');\n",
       "   div.jp-MarkdownOutput {font-family: 'Hind Siliguri', sans-serif; font-size: 100%;}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Hind+Siliguri&display=swap');\n",
    "   div.jp-MarkdownOutput {font-family: 'Hind Siliguri', sans-serif; font-size: 100%;}\n",
    "</style>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
