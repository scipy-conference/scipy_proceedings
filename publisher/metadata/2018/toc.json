{
  "toc": [
    {
      "title": "Dynamic Social Network Modeling of Diffuse Subcellular Morphologies",
      "paper_id": "Andrew_Durden",
      "abstract": [
        "The use of fluorescence microscopy has catalyzed new insights into biological\nfunction, and spurred the development of quantitative models from rich biomedical\nimage datasets. While image processing in some capacity is commonplace for\nextracting and modeling quantitative knowledge from biological systems at varying\nscales, general-purpose approaches for more advanced modeling are few. In\nparticular, diffuse organellar morphologies, such as mitochondria or actin\nmicrotubules, have few if any established spatiotemporal modeling strategies,\nall but discarding critically important sources of signal from a biological system.\nHere, we discuss initial work into building spatiotemporal models of diffuse\nsubcellular morphologies, using mitochondrial protein patterns of\ncervical epithelial (HeLa) cells. We leverage principles of graph theory and\nconsider the diffuse mitochondrial patterns as a social network: a collection of\nvertices interconnected by weighted and directed edges, indicating spatial\nrelationships. By studying the changing topology of the social networks over\ntime, we gain a mechanistic understanding of the types of stresses imposed on\nthe mitochondria by external stimuli, and can relate these effects in terms of\ngraph theoretic quantities such as centrality, connectivity, and flow. We\ndemonstrate how the mitochondrial pattern can be faithfully represented\nparametrically using a learned mixture of Gaussians, which is then perturbed\nto match the spatiotemporal evolution of the mitochondrial patterns over time.\nThe learned Gaussian components can then be converted to graph Laplacians,\nformally defining a network, and the changes in the topology of the Laplacians\ncan yield biologically-meaningful interpretations of the evolving morphology.\nWe hope to leverage these preliminary results to implement a bioimaging\ntoolbox, using existing open source packages in the scientific Python\necosystem (SciPy, NumPy, scikit-image, OpenCV), which builds dynamic social\nnetwork models from time series fluorescence images of diffuse subcellular\nprotein patterns. This will enable a direct quantitative comparison of network\nstructure over time and between cells exposed to different conditions."
      ],
      "page": {
        "stop": 7,
        "start": 1
      },
      "keywords": "Biomedical Imaging, Graph Theory, Social Networks",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-000",
      "pages": 7,
      "author_email": [
        "andrewdurden@uga.edu",
        "allyson.loy@uga.edu",
        "bjreaves@uga.edu",
        "Mojtaba@uga.edu",
        "abigail.courtney@uga.edu",
        "fquinn@uga.edu",
        "chakracs@pitt.edu",
        "spq@uga.edu"
      ],
      "author_institution": [
        "Department of Computer Science, University of Georgia, Athens, GA 30602 USA",
        "Department of Microbiology, University of Georgia, Athens, GA 30602 USA",
        "Department of Infectious Diseases, University of Georgia, Athens, GA 30602 USA",
        "Department of Computer Science, University of Georgia, Athens, GA 30602 USA",
        "Department of Microbiology, University of Georgia, Athens, GA 30602 USA",
        "Department of Infectious Diseases, University of Georgia, Athens, GA 30602 USA",
        "Department of Computational and Systems Biology, University of Pittsburgh, Pittsburgh, PA 15232 USA",
        "Department of Computer Science, University of Georgia, Athens, GA 30602 USA",
        "Department of Cellular Biology, University of Georgia, Athens, GA 30602 USA"
      ],
      "copyright_holder": "Andrew Durden et al.",
      "author": [
        "Andrew Durden",
        "Allyson T Loy",
        "Barbara Reaves",
        "Mojtaba Fazli",
        "Abigail Courtney",
        "Frederick D Quinn",
        "S Chakra Chennubhotla",
        "Shannon P Quinn"
      ],
      "author_institution_map": {
        "Barbara Reaves": [
          "Department of Infectious Diseases, University of Georgia, Athens, GA 30602 USA"
        ],
        "S Chakra Chennubhotla": [
          "Department of Computational and Systems Biology, University of Pittsburgh, Pittsburgh, PA 15232 USA"
        ],
        "Abigail Courtney": [
          "Department of Microbiology, University of Georgia, Athens, GA 30602 USA"
        ],
        "Allyson T Loy": [
          "Department of Microbiology, University of Georgia, Athens, GA 30602 USA"
        ],
        "Shannon P Quinn": [
          "Department of Computer Science, University of Georgia, Athens, GA 30602 USA",
          "Department of Cellular Biology, University of Georgia, Athens, GA 30602 USA"
        ],
        "Andrew Durden": [
          "Department of Computer Science, University of Georgia, Athens, GA 30602 USA"
        ],
        "Mojtaba Fazli": [
          "Department of Computer Science, University of Georgia, Athens, GA 30602 USA"
        ],
        "Frederick D Quinn": [
          "Department of Infectious Diseases, University of Georgia, Athens, GA 30602 USA"
        ]
      },
      "bibliography": "mybib",
      "authors": "Andrew Durden, Allyson T Loy, Barbara Reaves, Mojtaba Fazli, Abigail Courtney, Frederick D Quinn, S Chakra Chennubhotla, Shannon P Quinn"
    },
    {
      "title": "Cloudknot: A Python Library to Run your Existing Code on AWS Batch",
      "paper_id": "adam_richie-halford",
      "abstract": [
        "We introduce Cloudknot, a software library that simplifies cloud-based\ndistributed computing by programmatically executing user-defined\nfunctions (UDFs) in AWS Batch. It takes as input a Python function,\npackages it as a container, creates all the necessary AWS constituent\nresources to submit jobs, monitors their execution and gathers the\nresults, all from within the Python environment. Cloudknot minimizes\nthe cognitive load of learning a new API by introducing only one new\nobject and using the familiar map method. It overcomes\nlimitations of previous similar libraries, such as Pywren, that runs\nUDFs on AWS Lambda, because most data science workloads exceed the\ncurrent limits of AWS Lambda on execution time, RAM, and local\nstorage."
      ],
      "page": {
        "stop": 14,
        "start": 8
      },
      "keywords": "Cloud computing, Amazon Web Services, Distributed computing",
      "video": "https://youtu.be/D9LPzqoZ3f8",
      "doi": "10.25080/Majora-4af1f417-001",
      "pages": 7,
      "author_email": ["richiehalford@gmail.com", "arokem@gmail.com"],
      "author_institution": [
        "University of Washington, Seattle, WA",
        "University of Washington, Seattle, WA"
      ],
      "copyright_holder": "Adam Richie-Halford et al.",
      "author": ["Adam Richie-Halford", "Ariel Rokem"],
      "author_institution_map": {
        "Adam Richie-Halford": ["University of Washington, Seattle, WA"],
        "Ariel Rokem": ["University of Washington, Seattle, WA"]
      },
      "bibliography": "mybib",
      "authors": "Adam Richie-Halford, Ariel Rokem"
    },
    {
      "title": "Equity, Scalability, and Sustainability of Data Science Infrastructure",
      "paper_id": "anthony_suen_laura_noren_alan_liang_andrea_tu",
      "abstract": [
        "We seek to understand the current state of equity, scalability, and sustainability of data science education infrastructure in both the U.S. and Canada. Our analysis of the technological, funding, and organizational structure of four types of institutions shows an increasing divergence in the ability of universities across the United States to provide students with accessible data science education infrastructure, primarily JupyterHub. We observe that generally liberal arts colleges, community colleges, and other institutions with limited IT staff and experience have greater difficulty setting up and maintaining JupyterHub, compared to well-funded private institutions or large public research universities with a deep technical bench of IT staff. However, by leveraging existing public-private partnerships and the experience of Canada’s national JupyterHub (Syzygy), the U.S. has an opportunity to provide a wider range of institutions and students access to JupyterHub."
      ],
      "page": {
        "stop": 17,
        "start": 15
      },
      "keywords": "data science education, Jupyter, Jupyterhub, higher education",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-002",
      "pages": 3,
      "author_email": [
        "anthonysuen@berkeley.edu",
        "laura.noren@nyu.edu",
        "alanliang@berkeley.edu",
        "andrea.tu@berkeley.edu"
      ],
      "author_institution": [
        "University of California, Berkeley",
        "New York University",
        "University of California, Berkeley",
        "University of California, Berkeley"
      ],
      "copyright_holder": "Anthony Suen et al.",
      "author": ["Anthony Suen", "Laura Norén", "Alan Liang", "Andrea Tu"],
      "author_institution_map": {
        "Laura Norén": ["New York University"],
        "Andrea Tu": ["University of California, Berkeley"],
        "Alan Liang": ["University of California, Berkeley"],
        "Anthony Suen": ["University of California, Berkeley"]
      },
      "bibliography": "",
      "authors": "Anthony Suen, Laura Norén, Alan Liang, Andrea Tu"
    },
    {
      "title": "Composable Multi-Threading and Multi-Processing for Numeric Libraries",
      "paper_id": "anton_malakhov",
      "abstract": [
        "Python is popular among scientific communities that value its simplicity and power, especially as it comes along with numeric libraries such as NumPy, SciPy, Dask, and Numba.\nAs CPU core counts keep increasing, these modules can make use of many cores via multi-threading for efficient multi-core parallelism.\nHowever, threads can interfere with each other leading to overhead and inefficiency if used together in a single application on machines with a large number of cores.\nThis performance loss can be prevented if all multi-threaded modules are coordinated.\nThis paper continues the work started in AMala16 by introducing more approaches to coordination for both multi-threading and multi-processing cases.\nIn particular, we investigate the use of static settings, limiting the number of simultaneously active OpenMP parallel regions, and optional parallelism with Intel® Threading Building Blocks (Intel® TBB).\nWe will show how these approaches help to unlock additional performance for numeric applications on multi-core systems."
      ],
      "page": {
        "stop": 24,
        "start": 18
      },
      "keywords": "Multi-threading, Multi-processing, Oversubscription, Parallel Computations, Nested Parallelism, Multi-core, Python, GIL, Dask, Joblib, NumPy, SciPy, TBB, OpenMP",
      "video": "https://youtu.be/HKjM3peINtw",
      "doi": "10.25080/Majora-4af1f417-003",
      "pages": 7,
      "author_email": [
        "Anton.Malakhov@intel.com",
        "david.a.liu@intel.com",
        "Anton.V.Gorshkov@intel.com",
        "Terry.L.Wilmarth@intel.com"
      ],
      "author_institution": [
        "Intel Corporation",
        "Intel Corporation",
        "Intel Corporation",
        "Intel Corporation"
      ],
      "copyright_holder": "Anton Malakhov et al.",
      "author": [
        "Anton Malakhov",
        "David Liu",
        "Anton Gorshkov",
        "Terry Wilmarth"
      ],
      "author_institution_map": {
        "Anton Malakhov": ["Intel Corporation"],
        "Anton Gorshkov": ["Intel Corporation"],
        "David Liu": ["Intel Corporation"],
        "Terry Wilmarth": ["Intel Corporation"]
      },
      "bibliography": "",
      "authors": "Anton Malakhov, David Liu, Anton Gorshkov, Terry Wilmarth"
    },
    {
      "title": "The Econ-ARK and HARK: Open Source Tools for Computational Economics",
      "paper_id": "carroll_et_al",
      "abstract": [
        "The Economics Algorithmic Repository and toolKit (Econ-ARK) aims\nto become a focal resource for computational economics. Its first ‘framework,’ the\nHeterogeneous Agent Resources and Toolkit (HARK),\nprovides a modern, robust, transparent set of tools to solve a class of macroeconomic models\nwhose usefulness has become increasingly apparent both for economic policy and for research\npurposes, but whose adoption has been limited because the existing literature derives from\nidiosyncratic, hand-crafted, and often impenetrable legacy code. We expect future Econ-ARK\nframeworks (e.g., for analysis of the transmission of beliefs through agents' social networks)\nwill draw heavily on key elements of the existing HARK framework, including the API, the\nstructure, and documentation standards."
      ],
      "page": {
        "stop": 30,
        "start": 25
      },
      "keywords": "Heterogeneous-Agent Resources toolKit, econ-ark, computational economics, economic modeling",
      "video": "https://youtu.be/1ytEhrnwu6A",
      "doi": "10.25080/Majora-4af1f417-004",
      "pages": 6,
      "author_email": [
        "ccarroll@jhu.edu",
        "akaufman10@gmail.com",
        "jacqueline.kazil@capitalone.com",
        "npalmer.professional@gmail.com",
        "mnwecon@udel.edu"
      ],
      "author_institution": [
        "Johns Hopkins University",
        "Woodrow Wilson School of Public Policy",
        "Capital One",
        "Econ-ARK",
        "University of Delaware"
      ],
      "copyright_holder": "Christopher D. Carroll et al.",
      "author": [
        "Christopher D. Carroll",
        "Alexander M. Kaufman",
        "Jacqueline L. Kazil",
        "Nathan M. Palmer",
        "Matthew N. White"
      ],
      "author_institution_map": {
        "Alexander M. Kaufman": ["Woodrow Wilson School of Public Policy"],
        "Nathan M. Palmer": ["Econ-ARK"],
        "Matthew N. White": ["University of Delaware"],
        "Christopher D. Carroll": ["Johns Hopkins University"],
        "Jacqueline L. Kazil": ["Capital One"]
      },
      "bibliography": "",
      "authors": "Christopher D. Carroll, Alexander M. Kaufman, Jacqueline L. Kazil, Nathan M. Palmer, Matthew N. White"
    },
    {
      "title": "Developing a Start-to-Finish Pipeline for Accelerometer-Based Activity Recognition Using Long Short-Term Memory Recurrent Neural Networks",
      "paper_id": "christian_mcdaniel",
      "abstract": [
        "Increased prevalence of smartphones and wearable devices has facilitated the collection of triaxial accelerometer data for numerous Human Activity Recognition (HAR) tasks. Concurrently, advances in the theory and implementation of long short-term memory (LSTM) recurrent neural networks (RNNs) has made it possible to process this data in its raw form, enabling on-device online analysis. In this two-part experiment, we have first amassed the results from thirty studies and reported their methods and key findings in a meta-analysis style review. We then used these findings to guide our development of a start-to-finish data analysis pipeline, which we implemented on a commonly used open-source dataset in a proof of concept fashion. The pipeline addresses the large disparities in model hyperparameter settings and ensures the avoidance of potential sources of data leakage that were identified in the literature. Our pipeline uses a heuristic-based algorithm to tune a baseline LSTM model over an expansive hyperparameter search space and trains the model on standardized windowed accelerometer signals alone. We find that we outperform other baseline models trained on this data and are able to compete with benchmark results from complex models trained on higher-dimensional data."
      ],
      "page": {
        "stop": 40,
        "start": 31
      },
      "keywords": "Neural Network, Human Activity Recognition, Recurrent Neural Network, Long Short-Term Memory, Accelerometer, Machine Learning, Data Analysis, Data Science, Hyperparameter Optimization, Hyperparameter",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-005",
      "pages": 10,
      "author_email": ["clm121@uga.edu", "spq@uga.edu"],
      "author_institution": ["University of Georgia", "University of Georgia"],
      "copyright_holder": "Christian McDaniel et al.",
      "author": ["Christian McDaniel", "Shannon Quinn"],
      "author_institution_map": {
        "Christian McDaniel": ["University of Georgia"],
        "Shannon Quinn": ["University of Georgia"]
      },
      "bibliography": "citations",
      "authors": "Christian McDaniel, Shannon Quinn"
    },
    {
      "title": "Practical Applications of Astropy",
      "paper_id": "david_shupe",
      "abstract": [
        "Packages developed under the auspices of the Astropy Project (astropy2013,\nastropy2018) address many common problems faced by astronomers in their\ncomputational projects.\nIn this paper we describe how capabilities\nprovided by Astropy have been employed in two current projects. The data system for the\nZwicky Transient Facility processes a terabyte of image data every night, with a lights-out\nautomated pipeline that produces difference images about ten minutes after the receipt of\nevery exposure. Astropy is used extensively in the astrometry and light-curve-generation\nmodules, making especially heavy use of FITS header manipulation,\ntable I/O, and coordinate conversion and matching. The second project is a web application\nmade with Plotly Dash for proposal studies for the Origins Space Telescope. The astropy.cosmology\nmodule provided easy redshifting of our template galaxy spectrum, and astropy.units enabled\nthe porting of an instrument sensitivity function to Python, with verification that a very\ncomplex combination of units resulted in a dimensionless signal-to-noise value."
      ],
      "page": {
        "stop": 47,
        "start": 41
      },
      "keywords": "astronomy, data processing",
      "video": "https://youtu.be/2GTLkH5sfJc",
      "doi": "10.25080/Majora-4af1f417-006",
      "pages": 7,
      "author_email": [
        "shupe@ipac.caltech.edu",
        "fmasci@ipac.caltech.edu",
        "laher@ipac.caltech.edu",
        "rusholme@ipac.caltech.edu",
        "armus@ipac.caltech.edu"
      ],
      "author_institution": [
        "Caltech/IPAC",
        "Caltech/IPAC",
        "Caltech/IPAC",
        "Caltech/IPAC",
        "Caltech/IPAC"
      ],
      "copyright_holder": "David Shupe et al.",
      "author": [
        "David Shupe",
        "Frank Masci",
        "Russ Laher",
        "Ben Rusholme",
        "Lee Armus"
      ],
      "author_institution_map": {
        "Ben Rusholme": ["Caltech/IPAC"],
        "Russ Laher": ["Caltech/IPAC"],
        "David Shupe": ["Caltech/IPAC"],
        "Lee Armus": ["Caltech/IPAC"],
        "Frank Masci": ["Caltech/IPAC"]
      },
      "bibliography": "mybib",
      "authors": "David Shupe, Frank Masci, Russ Laher, Ben Rusholme, Lee Armus"
    },
    {
      "title": "EarthSim: Flexible Environmental Simulation Workflows Entirely Within Jupyter Notebooks",
      "paper_id": "dharhas_pothina",
      "abstract": [
        "Building environmental simulation workflows is typically a slow process involving multiple\nproprietary desktop tools that do not interoperate well. In this work, we demonstrate building\nflexible, lightweight workflows entirely in Jupyter notebooks. We demonstrate these capabilities\nthrough examples in hydrology and hydrodynamics using the AdH (Adaptive Hydraulics) and\nGSSHA (Gridded Surface Subsurface Hydrologic Analysis) simulators. The goal of this work is\nto provide a set of tools that work well together and with the existing scientific python ecosystem,\nthat can be used in browser based environments and that can easily be reconfigured and repurposed\nas needed to rapidly solve specific emerging issues such as hurricanes or dam failures.",
        "As part of this work, extensive improvements were made to several general-purpose open source\npackages, including support for annotating and editing plots and maps in Bokeh and HoloViews,\nrendering large triangular meshes and regridding large raster data in HoloViews, GeoViews, and\nDatashader, and widget libraries for Param. In addition, two new open source projects are being\nreleased, one for triangular mesh generation (Filigree) and one for environmental data access (Quest)."
      ],
      "page": {
        "stop": 55,
        "start": 48
      },
      "keywords": "python, visualization, workflows, environmental simulation, hydrology, hydrodynamics, grid generation",
      "video": "https://youtu.be/KTbd_oUkP4Q",
      "doi": "10.25080/Majora-4af1f417-007",
      "pages": 8,
      "author_email": [
        "Dharhas.Pothina@erdc.dren.mil",
        "prudiger@anaconda.com",
        "jbednar@anaconda.com",
        "Scott.Christensen@erdc.dren.mil",
        "Kevin.Winters@erdc.dren.mil",
        "Kimberly.C.Pevey@erdc.dren.mil",
        "cball@anaconda.com",
        "gregshipssoftware@gmail.com"
      ],
      "author_institution": [
        "US Army Engineer Research and Development Center",
        "Anaconda, Inc.",
        "Anaconda, Inc.",
        "US Army Engineer Research and Development Center",
        "US Army Engineer Research and Development Center",
        "US Army Engineer Research and Development Center",
        "Anaconda, Inc.",
        "Anaconda, Inc."
      ],
      "copyright_holder": "Dharhas Pothina et al.",
      "author": [
        "Dharhas Pothina",
        "Philipp J. F. Rudiger",
        "James A Bednar",
        "Scott Christensen",
        "Kevin Winters",
        "Kimberly Pevey",
        "Christopher E. Ball",
        "Gregory Brener"
      ],
      "author_institution_map": {
        "Kevin Winters": ["US Army Engineer Research and Development Center"],
        "Christopher E. Ball": ["Anaconda, Inc."],
        "Gregory Brener": ["Anaconda, Inc."],
        "Philipp J. F. Rudiger": ["Anaconda, Inc."],
        "Scott Christensen": [
          "US Army Engineer Research and Development Center"
        ],
        "James A Bednar": ["Anaconda, Inc."],
        "Kimberly Pevey": ["US Army Engineer Research and Development Center"],
        "Dharhas Pothina": ["US Army Engineer Research and Development Center"]
      },
      "bibliography": "",
      "authors": "Dharhas Pothina, Philipp J. F. Rudiger, James A Bednar, Scott Christensen, Kevin Winters, Kimberly Pevey, Christopher E. Ball, Gregory Brener"
    },
    {
      "title": "Safe handling instructions for missing data",
      "paper_id": "dillon_niederhut",
      "abstract": [
        "In machine learning tasks, it is common to handle missing data by removing observations with missing values, or replacing missing data with the mean value for its feature. To show why this is problematic, we use listwise deletion and mean imputing to recover missing values from artificially created datasets, and we compare those models against ones with full information. Unless quite strong independence assumptions are met, we observe large biases in the resulting coefficients and an increase in the model's prediction error. We include a set of recommendations for handling missing data safely, and a case study showing how to put those recommendations into practice."
      ],
      "page": {
        "stop": 60,
        "start": 56
      },
      "keywords": "data science, missing data, imputation",
      "video": "https://youtu.be/2gkw2T5jAfo",
      "doi": "10.25080/Majora-4af1f417-008",
      "pages": 5,
      "author_email": ["dniederhut@enthought.com"],
      "author_institution": ["Enthought, Inc."],
      "copyright_holder": "Dillon Niederhut.",
      "author": ["Dillon Niederhut"],
      "author_institution_map": {
        "Dillon Niederhut": ["Enthought, Inc."]
      },
      "bibliography": "",
      "authors": "Dillon Niederhut"
    },
    {
      "title": "Text and data mining scientific articles with allofplos",
      "paper_id": "elizabeth_seiver",
      "abstract": [
        "Mining scientific articles is hard when many of them are inaccessible\nbehind paywalls. The Public Library of Science (PLOS) is a non-profit\nOpen Access science publisher of the single largest journal (PLOS\nONE), whose articles are all freely available to read and re-use.\nallofplos is a Python package for maintaining a constantly growing\ncollection of PLOS's 230,000+ articles. It also efficiently\nparses these article files into Python data structures. This article will\ncover how allofplos keeps your articles up-to-date, and how to use it to\neasily access common article metadata and fuel your meta-research, with\nactual use cases from inside PLOS."
      ],
      "page": {
        "stop": 64,
        "start": 61
      },
      "keywords": "Text and data mining, metascience, open access, science publishing, scientific articles, XML",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-009",
      "pages": 4,
      "author_email": [
        "elizabeth.seiver@gmail.com",
        "mpacer.phd@gmail.com",
        "sebastian.bassi@globant.com"
      ],
      "author_institution": ["Netflix", "Globant"],
      "copyright_holder": "Elizabeth Seiver et al.",
      "author": ["Elizabeth Seiver", "M Pacer", "Sebastian Bassi"],
      "author_institution_map": {
        "Elizabeth Seiver": [],
        "Sebastian Bassi": ["Globant"],
        "M Pacer": ["Netflix"]
      },
      "bibliography": "",
      "authors": "Elizabeth Seiver, M Pacer, Sebastian Bassi"
    },
    {
      "title": "Sparse: A more modern sparse array library",
      "paper_id": "hameer_abbasi",
      "abstract": [
        "This paper is about sparse multi-dimensional arrays in Python. We discuss\ntheir applications, layouts, and current implementations in the SciPy\necosystem along with strengths and weaknesses. We then introduce a new\npackage for sparse arrays that builds on the legacy of the scipy.sparse\nimplementation, but supports more modern interfaces, dimensions greater\nthan two, and improved integration with newer array packages, like XArray\nand Dask. We end with performance benchmarks and notes on future\nwork.\nAdditionally, this work provides a concrete implementation of the recent\nNumPy array protocols to build generic array interfaces for improved\ninteroperability, and so may be useful for broader community discussion."
      ],
      "page": {
        "stop": 68,
        "start": 65
      },
      "keywords": "sparse, sparse arrays, sparse matrices, scipy.sparse, ndarray, ndarray interface",
      "video": "https://youtu.be/xH5eVcb1SlA",
      "doi": "10.25080/Majora-4af1f417-00a",
      "pages": 4,
      "author_email": ["hameerabbasi@yahoo.com"],
      "author_institution": ["TU Darmstadt"],
      "copyright_holder": "Hameer Abbasi.",
      "author": ["Hameer Abbasi"],
      "author_institution_map": {
        "Hameer Abbasi": ["TU Darmstadt"]
      },
      "bibliography": "references",
      "authors": "Hameer Abbasi"
    },
    {
      "title": "Bringing ipywidgets Support to plotly.py",
      "paper_id": "jon_mease",
      "abstract": [
        "Plotly.js is a declarative JavaScript data visualization library built on D3\nand WebGL that supports a wide range of statistical, scientific,\nfinancial, geographic, and 3-dimensional visualizations. Support for\ncreating Plotly.js visualizations from Python is provided by the plotly.py\nlibrary. Version 3 of plotly.py integrates ipywidgets support, providing\na host of benefits to plotly.py users working in the Jupyter notebook.\nThis paper describes the architecture of this new version of plotly.py,\nand presents examples of several of these benefits."
      ],
      "page": {
        "stop": 76,
        "start": 69
      },
      "keywords": "ipywidgets, plotly, jupyter, visualization",
      "video": "https://youtu.be/1ndo6C1KWjI",
      "doi": "10.25080/Majora-4af1f417-00b",
      "pages": 8,
      "author_email": ["jon.mease@jhuapl.edu"],
      "author_institution": ["Johns Hopkins Applied Physics Laboratory"],
      "copyright_holder": "Jon Mease.",
      "author": ["Jon Mease"],
      "author_institution_map": {
        "Jon Mease": ["Johns Hopkins Applied Physics Laboratory"]
      },
      "bibliography": "mybib",
      "authors": "Jon Mease"
    },
    {
      "title": "WrightSim: Using PyCUDA to Simulate Multidimensional Spectra",
      "paper_id": "kyle_sunden",
      "abstract": [
        "Nonlinear multidimensional spectroscopy (MDS) is a powerful experimental technique used to interrogate complex chemical systems.\nMDS promises to reveal energetics, dynamics, and coupling features of and between the many quantum-mechanical states that these systems contain.\nIn practice, simulation is typically required to connect measured MDS spectra with these microscopic physical phenomena.\nWe present an open-source Python package, WrightSim, designed to simulate MDS.\nNumerical integration is used to evolve the system as it interacts with several electric fields in the course of a multidimensional experiment.\nThis numerical approach allows WrightSim to fully account for finite pulse effects that are commonly ignored.\nWrightSim is made up of modules that can be exchanged to accommodate many different experimental setups.\nSimulations are defined through a Python interface that is designed to be intuitive for experimentalists and theorists alike.\nWe report several algorithmic improvements that make WrightSim faster than previous implementations.\nWe demonstrated the effect of parallelizing the simulation, both with CPU multiprocessing and GPU (CUDA) multithreading.\nTaken together, algorithmic improvements and parallelization have made WrightSim multiple orders of magnitude faster than previous implementations.\nWrightSim represents a large step towards the goal of a fast, accurate, and easy to use general purpose simulation package for multidimensional spectroscopy.\nTo our knowledge, WrightSim is the first openly licensed software package for these kinds of simulations.\nPotential further improvements are discussed."
      ],
      "page": {
        "stop": 83,
        "start": 77
      },
      "keywords": "Simulation, spectroscopy, PyCUDA, numerical integration, Quantum Mechanics, multidimensional",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-00c",
      "pages": 7,
      "author_email": [
        "sunden@wisc.edu",
        "blaise@untzag.com",
        "wright@chem.wisc.edu"
      ],
      "author_institution": [
        "University of Wisconsin-{}-Madison",
        "University of Wisconsin-{}-Madison",
        "University of Wisconsin-{}-Madison"
      ],
      "copyright_holder": "Kyle F Sunden et al.",
      "author": ["Kyle F Sunden", "Blaise J Thompson", "John C Wright"],
      "author_institution_map": {
        "Kyle F Sunden": ["University of Wisconsin-{}-Madison"],
        "John C Wright": ["University of Wisconsin-{}-Madison"],
        "Blaise J Thompson": ["University of Wisconsin-{}-Madison"]
      },
      "bibliography": "bib",
      "authors": "Kyle F Sunden, Blaise J Thompson, John C Wright"
    },
    {
      "title": "Exploring the Extended Kalman Filter for GPS Positioning Using Simulated User and Satellite Track Data",
      "paper_id": "mark_wickert_247",
      "abstract": [
        "This paper describes a Python computational tool for exploring the use of the\nextended Kalman filter (EKF) for position estimation using the Global Positioning System (GPS)\npseudorange measurements. The development was motivated by the need for an example\ngenerator in a training class on Kalman filtering, with emphasis on GPS. In operation of\nthe simulation framework both user and satellite trajectories are played through the simulation.\nThe User trajectory\nis input in local east-north-up (ENU) coordinates and satellites tracks, specified by\nthe C/A code PRN number, are propagated using the Python package SGP4 using two-line element (TLE)\ndata available from Celestrak."
      ],
      "page": {
        "stop": 90,
        "start": 84
      },
      "keywords": "Global positioning system, Kalman filter, Extended Kalman filter,",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-00d",
      "pages": 7,
      "author_email": ["mwickert@uccs.edu", "csiddapp@uccs.edu"],
      "author_institution": [
        "University of Colorado Colorado Springs",
        "University of Colorado Colorado Springs"
      ],
      "copyright_holder": "Mark Wickert et al.",
      "author": ["Mark Wickert", "Chiranth Siddappa"],
      "author_institution_map": {
        "Mark Wickert": ["University of Colorado Colorado Springs"],
        "Chiranth Siddappa": ["University of Colorado Colorado Springs"]
      },
      "bibliography": "",
      "authors": "Mark Wickert, Chiranth Siddappa"
    },
    {
      "title": "Real-Time Digital Signal Processing Using pyaudio\\_helper and the ipywidgets",
      "paper_id": "mark_wickert_250",
      "abstract": [
        "The focus of this paper is on teaching real-time digital signal processing to\nelectrical and computer engineers using the Jupyter notebook and the code\nmodule pyaudio\\_helper, which is a component of the package\nscikit-dsp-comm. Specifically, we show how easy it is to design, prototype, and\ntest using PC-based instrumentation, real-time DSP algorithms for processing\nanalog signal inputs and returning analog signal outputs, all within the Jupyter\nnotebook. A key feature is that real-time algorithm prototyping is simplified\nby configuring a few attributes of a DSP\\_io\\_stream object from the\npyaudio\\_helper module, leaving the developer to focus on the real-time DSP\ncode contained in a callback function, using a template notebook cell.\nReal-time control of running code is provided by ipywidgets. The PC-based\ninstrumentation aspect allows measurement of the analog input/output (I/O) to be\ncaptured, stored in text files, and then read back into the notebook to\ncompare with the original design expectations via matplotlib plots.\nIn a typical\napplication slider widgets are used to change variables in the callback.\nOne and two channel audio applications as well as algorithms for complex\nsignal (in-phase/quadrature) waveforms, as found in software-defined radio,\ncan also be developed. The analog I/O devices that can be\ninterfaced are both internal and via USB external sound interfaces. The\nsampling rate, and hence the bandwidth of the signal that can be\nprocessed, is limited by the operating system audio subsystem capabilities,\nbut is at least 48 KHz and often 96 kHz."
      ],
      "page": {
        "stop": 98,
        "start": 91
      },
      "keywords": "digital signal processing, pyaudio, real-time, scikit-dsp-comm",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-00e",
      "pages": 8,
      "author_email": ["mwickert@uccs.edu"],
      "author_institution": ["University of Colorado Colorado Springs"],
      "copyright_holder": "Mark Wickert.",
      "author": ["Mark Wickert"],
      "author_institution_map": {
        "Mark Wickert": ["University of Colorado Colorado Springs"]
      },
      "bibliography": "",
      "authors": "Mark Wickert"
    },
    {
      "title": "Organic Molecules in Space: Insights from the NASA Ames Molecular Database in the era of the James Webb Space Telescope",
      "paper_id": "matthew_shannon",
      "abstract": [
        "We present the software tool pyPAHdb to the scientific astronomical\ncommunity, which is used to characterize emission from one of the\nmost prevalent types of organic molecules in space, namely\npolycyclic aromatic hydrocarbons (PAHs). It leverages the detailed\nstudies of organic molecules done at the NASA Ames Research\nCenter. pyPAHdb is a streamlined Python version of the NASA Ames\nPAH IR Spectroscopic Database (PAHdb; www.astrochemistry.org/pahdb) suite of IDL tools. PAHdb\nhas been extensively used to analyze and interpret the PAH\nsignature from a plethora of emission sources, ranging from\nsolar-system objects to entire galaxies. pyPAHdb decomposes\nastronomical PAH emission spectra into contributing PAH sub-classes\nin terms of charge and size using a database-fitting technique. The\ninputs for the fit are spectra constructed using the spectroscopic\nlibraries of PAHdb and take into account the detailed photo-physics\nof the PAH excitation/emission process."
      ],
      "page": {
        "stop": 105,
        "start": 99
      },
      "keywords": "astronomy, databases, fitting, data analysis",
      "video": "",
      "doi": "10.25080/Majora-4af1f417-00f",
      "pages": 7,
      "author_email": [
        "Matthew.J.Shannon@nasa.gov",
        "Christiaan.Boersma@nasa.gov"
      ],
      "author_institution": [
        "Universities Space Research Association, Columbia, MD",
        "NASA Ames Research Center, MS245-6, Moffett Field, CA 94035-1000",
        "San José State University Research Foundation, 210 N 4th St Fl 4, San Jose, CA 95112",
        "NASA Ames Research Center, MS245-6, Moffett Field, CA 94035-1000"
      ],
      "copyright_holder": "Matthew J. Shannon et al.",
      "author": ["Matthew J. Shannon", "Christiaan Boersma"],
      "author_institution_map": {
        "Matthew J. Shannon": [
          "Universities Space Research Association, Columbia, MD",
          "NASA Ames Research Center, MS245-6, Moffett Field, CA 94035-1000"
        ],
        "Christiaan Boersma": [
          "San José State University Research Foundation, 210 N 4th St Fl 4, San Jose, CA 95112",
          "NASA Ames Research Center, MS245-6, Moffett Field, CA 94035-1000"
        ]
      },
      "bibliography": "bib",
      "authors": "Matthew J. Shannon, Christiaan Boersma"
    },
    {
      "title": "Harnessing the Power of Scientific Python to Investigate Biogeochemistry and Metaproteomes of the Central Pacific Ocean",
      "paper_id": "n_held",
      "abstract": [
        "Oceanographic expeditions commonly generate millions of data points for various chemical, biological, and physical features, all in different formats. Scientific Python tools are extremely useful for synthesizing this data to make sense of major trends in the changing ocean environment. In this paper, we present our application of scientific Python to investigate metaproteome data from the oxygen-depleted Central Pacific Ocean. The microbial proteins of this region are major drivers of biogeochemical cycles, and represent a living proxy of the ancient anoxic ocean. They also provide a look into the trajectory of the ocean in the face of rising temperatures, which cause deoxygenation. We assessed 103 metaproteome samples collected in the Central Pacific Ocean on the 2016 ProteOMZ cruise. This data represents \\textasciitilde{}60,000 identified proteins and over 6 million datapoints, in addition to over 6,600 corresponding chemical, physical, and biological metadata points.",
        "An interactive data analysis tool which enables the scientific user to visualize and interrogate patterns in these large metaproteomic datasets in conjunction with hydrographic features was not previously available. Bench scientists who would like to use this oceanographic data to gain insight into marine biogeochemical cycles were at a disadvantage as no tool existed to query these complex datasets in a visually meaningful way. Our goal was to provide a graphical visualization tool to enhance the exploration of these complex dataset; specifically, using interactive tools to enable users the ability to filter and automatically generate plots from slices of large metaproteomic and hydrographic datasets. We developed a Bokeh application BOKEH for data exploration which allows the user to hone in on proteins of interest using widgets. The user can then explore relationships between protein abundance and water column depth, hydrographic data, and taxonomic origin. The result is a complete and interactive visualization tool for interrogating a multivariate oceanographic dataset, which helped us to demonstrate a strong relationship between chemical, physical, and biological variables and the microbial proteins expressed. Because it was impossible to display all the proteins at once in the Bokeh application, we additionally describe an application of Holoviews/Datashader HOLOVIEWS, DATASHADER to this data, which further highlights the extreme differences between oxygen rich surface waters and the oxygen poor mesopelagic. This application can be easily adapted to new datasets, and is already proving to be a useful tool for exploring patterns in ocean protein abundance."
      ],
      "page": {
        "stop": 112,
        "start": 106
      },
      "keywords": "oceanography, microbial ecology, biogeochemistry, omics, visualization, bokeh, datashader, holoviews, pandas, dask, jupyter",
      "video": "https://youtu.be/WYmAu0GiSU4",
      "doi": "10.25080/Majora-4af1f417-010",
      "pages": 7,
      "author_email": [
        "nheld@whoi.edu",
        "jsaunders@whoi.edu",
        "jfutrelle@whoi.edu",
        "msaito@whoi.edu"
      ],
      "author_institution": [
        "Massachusetts Institute of Technology, Cambridge, MA",
        "Woods Hole Oceanographic Institution, Woods Hole, MA",
        "Woods Hole Oceanographic Institution, Woods Hole, MA",
        "Massachusetts Institute of Technology, Cambridge, MA",
        "Woods Hole Oceanographic Institution, Woods Hole, MA",
        "Woods Hole Oceanographic Institution, Woods Hole, MA"
      ],
      "copyright_holder": "Noelle A. Held et al.",
      "author": [
        "Noelle A. Held",
        "Jaclyn K. Saunders",
        "Joe Futrelle",
        "Mak A. Saito"
      ],
      "author_institution_map": {
        "Mak A. Saito": [
          "Woods Hole Oceanographic Institution, Woods Hole, MA"
        ],
        "Jaclyn K. Saunders": [
          "Woods Hole Oceanographic Institution, Woods Hole, MA",
          "Massachusetts Institute of Technology, Cambridge, MA"
        ],
        "Noelle A. Held": [
          "Massachusetts Institute of Technology, Cambridge, MA",
          "Woods Hole Oceanographic Institution, Woods Hole, MA"
        ],
        "Joe Futrelle": ["Woods Hole Oceanographic Institution, Woods Hole, MA"]
      },
      "bibliography": "",
      "authors": "Noelle A. Held, Jaclyn K. Saunders, Joe Futrelle, Mak A. Saito"
    },
    {
      "title": "Binder 2.0 - Reproducible, interactive, sharable environments for science at scale",
      "paper_id": "project_jupyter",
      "abstract": [
        "Binder is an open source web service that lets users create sharable,\ninteractive, reproducible environments in the cloud. It is powered by other\ncore projects in the open source ecosystem, including JupyterHub and\nKubernetes for managing cloud resources. Binder works with pre-existing\nworkflows in the analytics community, aiming to create interactive versions\nof repositories that exist on sites like GitHub with minimal extra effort\nneeded. This paper details several of the design decisions and goals that\nwent into the development of the current generation of Binder."
      ],
      "page": {
        "stop": 120,
        "start": 113
      },
      "keywords": "cloud computing, reproducibility, binder, mybinder.org, shared computing,\naccessibility, kubernetes, dev ops, jupyter, jupyterhub, jupyter notebooks, github,\npublishing, interactivity",
      "video": "https://youtu.be/KcC0W5LP9GM",
      "doi": "10.25080/Majora-4af1f417-011",
      "pages": 8,
      "author_email": [
        "",
        "",
        "",
        "",
        "",
        "tim@wildtreetech.com",
        "choldgraf@berkeley.edu",
        "",
        "",
        "",
        "mpacer.phd@gmail.com",
        "",
        "",
        "benjaminrk@gmail.com",
        "willingc@gmail.com"
      ],
      "author_institution": [
        "Project Jupyter",
        "UC Berkeley",
        "Project Jupyter",
        "",
        "Cal Poly, San Luis Obispo",
        "Wild Tree Tech, Switzerland",
        "UC Berkeley",
        "Netflix",
        "Simula Research Lab",
        "",
        "Netflix",
        "UC Berkeley",
        "UC Berkeley",
        "Simula Research Lab",
        "Cal Poly, San Luis Obispo"
      ],
      "copyright_holder": "Project Jupyter et al.",
      "author": [
        "Project Jupyter",
        "Matthias Bussonnier",
        "Jessica Forde",
        "Jeremy Freeman",
        "Brian Granger",
        "Tim Head",
        "Chris Holdgraf",
        "Kyle Kelley",
        "Gladys Nalvarte",
        "Andrew Osheroff",
        "M Pacer",
        "Yuvi Panda",
        "Fernando Perez",
        "Benjamin Ragan-Kelley",
        "Carol Willing"
      ],
      "author_institution_map": {
        "Project Jupyter": ["Project Jupyter"],
        "Carol Willing": ["Cal Poly, San Luis Obispo"],
        "Tim Head": ["Wild Tree Tech, Switzerland"],
        "Chris Holdgraf": ["UC Berkeley"],
        "Fernando Perez": ["UC Berkeley"],
        "Gladys Nalvarte": ["Simula Research Lab"],
        "Benjamin Ragan-Kelley": ["Simula Research Lab"],
        "Brian Granger": ["Cal Poly, San Luis Obispo"],
        "M Pacer": ["Netflix"],
        "Matthias Bussonnier": ["UC Berkeley"],
        "Yuvi Panda": ["UC Berkeley"],
        "Kyle Kelley": ["Netflix"],
        "Jessica Forde": ["Project Jupyter"],
        "Andrew Osheroff": [""],
        "Jeremy Freeman": [""]
      },
      "bibliography": "binderbib",
      "authors": "Project Jupyter, Matthias Bussonnier, Jessica Forde, Jeremy Freeman, Brian Granger, Tim Head, Chris Holdgraf, Kyle Kelley, Gladys Nalvarte, Andrew Osheroff, M Pacer, Yuvi Panda, Fernando Perez, Benjamin Ragan-Kelley, Carol Willing"
    },
    {
      "title": "Spatio-temporal analysis of socioeconomic neighborhoods: The Open Source Longitudinal Neighborhood Analysis Package (OSLNAP)",
      "paper_id": "serge_rey",
      "abstract": [
        "The neighborhood effects literature represents a wide span of the social\nsciences broadly concerned with the influence of spatial context on social\nprocesses. From the study of segregation dynamics, the relationships between the\nbuilt environment and health outcomes, to the impact of concentrated poverty on\nsocial efficacy, neighborhoods are a central construct in empirical work. From a\ndynamic lens, neighborhoods experience changes not only in their socioeconomic\ncomposition, but also in spatial extent; however, the literature has ignored the\nlatter source of change. In this paper, we discuss the development of a novel,\nspatially explicit tool: the Open Source Longitudinal Neighborhood Analysis\nPackage (OSLNAP) using the scientific Python ecosystem."
      ],
      "page": {
        "stop": 128,
        "start": 121
      },
      "keywords": "neighborhoods, GIS, clustering, dynamics",
      "video": "https://youtu.be/VWMj_rNb0io",
      "doi": "10.25080/Majora-4af1f417-012",
      "pages": 8,
      "author_email": [
        "sergio.rey@ucr.edu",
        "",
        "",
        "levi.john.wolf@bristol.ac.uk",
        ""
      ],
      "author_institution": [
        "Center for Geospatial Sciences, University of California, Riverside",
        "Center for Geospatial Sciences, University of California, Riverside",
        "Center for Geospatial Sciences, University of California, Riverside",
        "School of Geographical Sciences, University of Bristol",
        "Center for Geospatial Sciences, University of California, Riverside"
      ],
      "copyright_holder": "Sergio Rey et al.",
      "author": [
        "Sergio Rey",
        "Elijah Knaap",
        "Su Han",
        "Levi Wolf",
        "Wei Kang"
      ],
      "author_institution_map": {
        "Wei Kang": [
          "Center for Geospatial Sciences, University of California, Riverside"
        ],
        "Elijah Knaap": [
          "Center for Geospatial Sciences, University of California, Riverside"
        ],
        "Sergio Rey": [
          "Center for Geospatial Sciences, University of California, Riverside"
        ],
        "Levi Wolf": ["School of Geographical Sciences, University of Bristol"],
        "Su Han": [
          "Center for Geospatial Sciences, University of California, Riverside"
        ]
      },
      "bibliography": "reference",
      "authors": "Sergio Rey, Elijah Knaap, Su Han, Levi Wolf, Wei Kang"
    },
    {
      "title": "Design and Implementation of pyPRISM: A Polymer Liquid-State Theory Framework",
      "paper_id": "tyler_martin",
      "abstract": [
        "In this work, we describe the code structure, implementation, and usage of a\nPython-based, open-source framework, pyPRISM, for conducting polymer\nliquid-state theory calculations. Polymer Reference Interaction Site Model\n(PRISM) theory describes the equilibrium spatial-correlations,\nthermodynamics, and structure of liquid-like polymer systems and\nmacromolecular materials.  pyPRISM provides data structures, functions, and\nclasses that streamline predictive PRISM calculations and can be extended\nfor other tasks such as the coarse-graining of atomistic simulation\nforce-fields or the modeling of experimental scattering data. The goal of\nproviding this framework is to reduce the barrier to correctly and\nappropriately using PRISM theory and to provide a platform for rapid\ncalculations of the structure and thermodynamics of polymeric fluids and\npolymer nanocomposites."
      ],
      "page": {
        "stop": 136,
        "start": 129
      },
      "keywords": "polymer, materials science, modeling, theory",
      "video": "https://youtu.be/MYw-pmz02p0",
      "doi": "10.25080/Majora-4af1f417-013",
      "pages": 8,
      "author_email": [
        "tyler.martin@nist.gov",
        "tgartner@udel.edu",
        "ronald.jones@nist.gov",
        "chad.snyder@nist.gov",
        "arthij@udel.edu"
      ],
      "author_institution": [
        "National Institute of Standards and Technology",
        "Chemical and Biomolecular Engineering, University of Delaware",
        "National Institute of Standards and Technology",
        "National Institute of Standards and Technology",
        "Chemical and Biomolecular Engineering, University of Delaware",
        "Materials Science and Engineering, University of Delaware"
      ],
      "copyright_holder": "Tyler B. Martin et al.",
      "author": [
        "Tyler B. Martin",
        "Thomas E. Gartner III",
        "Ronald L. Jones",
        "Chad R. Snyder",
        "Arthi Jayaraman"
      ],
      "author_institution_map": {
        "Arthi Jayaraman": [
          "Chemical and Biomolecular Engineering, University of Delaware",
          "Materials Science and Engineering, University of Delaware"
        ],
        "Tyler B. Martin": ["National Institute of Standards and Technology"],
        "Chad R. Snyder": ["National Institute of Standards and Technology"],
        "Ronald L. Jones": ["National Institute of Standards and Technology"],
        "Thomas E. Gartner III": [
          "Chemical and Biomolecular Engineering, University of Delaware"
        ]
      },
      "bibliography": "mybib",
      "authors": "Tyler B. Martin, Thomas E. Gartner III, Ronald L. Jones, Chad R. Snyder, Arthi Jayaraman"
    },
    {
      "title": "A Bayesian’s journey to a better research workflow",
      "paper_id": "vamvourellis_corvellec",
      "abstract": [
        "This work began when the two authors met at a software development meeting.\nKonstantinos was building Bayesian models in his research and wanted to\nlearn how to better manage his research process. Marianne was working on\ndata analysis workflows in industry and wanted to learn more about Bayesian\nstatistics. In this paper, the authors present a Bayesian scientific\nresearch workflow for statistical analysis. Drawing on a case study in\nclinical trials, they demonstrate lessons that other scientists, not\nnecessarily Bayesian, could find useful in their own work. Notably, they can\nbe used to improve productivity and reproducibility in any computational\nresearch project."
      ],
      "page": {
        "stop": 144,
        "start": 137
      },
      "keywords": "Bayesian statistics, life sciences, clinical trials, probabilistic programming, Stan, PyStan",
      "video": "https://youtu.be/piQvcVala9I",
      "doi": "10.25080/Majora-4af1f417-014",
      "pages": 8,
      "author_email": [
        "k.vamvourellis@lse.ac.uk",
        "marianne.corvellec@igdore.org"
      ],
      "author_institution": [
        "London School of Economics and Political Science",
        "Institute for Globally Distributed Open Research and Education (IGDORE)"
      ],
      "copyright_holder": "Konstantinos Vamvourellis et al.",
      "author": ["Konstantinos Vamvourellis", "Marianne Corvellec"],
      "author_institution_map": {
        "Konstantinos Vamvourellis": [
          "London School of Economics and Political Science"
        ],
        "Marianne Corvellec": [
          "Institute for Globally Distributed Open Research and Education (IGDORE)"
        ]
      },
      "bibliography": "library",
      "authors": "Konstantinos Vamvourellis, Marianne Corvellec"
    },
    {
      "title": "Scalable Feature Extraction with Aerial and Satellite Imagery",
      "paper_id": "virginia_ng",
      "abstract": [
        "Deep learning techniques have greatly advanced the performance of the already rapidly developing field of computer vision, which powers a variety of emerging technologies—from facial recognition to augmented reality to self-driving cars. The remote sensing and mapping communities are particularly interested in extracting, understanding and mapping physical elements in the landscape. These mappable physical elements are called features, and can include both natural and synthetic objects of any scale, complexity and character. Points or polygons representing sidewalks, glaciers, playgrounds, entire cities, and bicycles are all examples of features. In this paper we present a method to develop deep learning tools and pipelines that generate features from aerial and satellite imagery at large scale. Practical applications include object detection, semantic segmentation and automatic mapping of general-interest features such as turn lane markings on roads, parking lots, roads, water, building footprints.",
        "We give an overview of our data preparation process, in which data from the Mapbox Satellite layer, a global imagery collection, is annotated with labels created from OpenStreetMap data using minimal manual effort. We then discuss the implementation of various state-of-the-art detection and semantic segmentation systems such as the improved version of You Only Look Once (YOLOv2), modified U-Net, Pyramid Scene Parsing Network (PSPNet), as well as specific adaptations for the aerial and satellite imagery domain. We conclude by discussing our ongoing efforts in improving our models and expanding their applicability across classes of features, geographical regions, and relatively novel data sources such as street-level and drone imagery."
      ],
      "page": {
        "stop": 151,
        "start": 145
      },
      "keywords": "computer vision, deep learning, neural networks, satellite imagery, aerial imagery",
      "video": "https://youtu.be/3AuRW9kq89g",
      "doi": "10.25080/Majora-4af1f417-015",
      "pages": 7,
      "author_email": ["virginia@mapbox.com", "hofmann@mapbox.com"],
      "author_institution": ["Mapbox", "Mapbox"],
      "copyright_holder": "Virginia Ng et al.",
      "author": ["Virginia Ng", "Daniel Hofmann"],
      "author_institution_map": {
        "Daniel Hofmann": ["Mapbox"],
        "Virginia Ng": ["Mapbox"]
      },
      "bibliography": "",
      "authors": "Virginia Ng, Daniel Hofmann"
    },
    {
      "title": "signac: A Python framework for data and workflow management",
      "paper_id": "vyas_ramasubramani",
      "abstract": [
        "Computational research requires versatile data and workflow management tools that can easily adapt to the highly dynamic requirements of scientific investigations.\nMany existing tools require strict adherence to a particular usage pattern, so researchers often use less robust ad hoc solutions that they find easier to adopt.\nThe resulting data fragmentation and methodological incompatibilities significantly impede research.\nOur talk showcases signac, an open-source Python framework that offers highly modular and scalable solutions for this problem.\nNamed for the Pointillist painter Paul Signac, the framework's powerful workflow management tools enable users to construct and automate workflows that transition seamlessly from laptops to HPC clusters.\nCrucially, the underlying data model is completely independent of the workflow.\nThe flexible, serverless, and schema-free signac database can be introduced into other workflows with essentially no overhead and no recourse to the signac workflow model.\nAdditionally, the data model's simplicity makes it easy to parse the underlying data without using signac at all.\nThis modularity and simplicity eliminates significant barriers for consistent data management across projects, facilitating improved provenance management and data sharing with minimal overhead."
      ],
      "page": {
        "stop": 159,
        "start": 152
      },
      "keywords": "data management, database, data sharing, provenance, computational workflow, hpc",
      "video": "https://youtu.be/CCKQH1M2uR4",
      "doi": "10.25080/Majora-4af1f417-016",
      "pages": 8,
      "author_email": [
        "vramasub@umich.edu",
        "csadorf@umich.edu",
        "pdodd@umich.edu",
        "bdice@umich.edu",
        "sglotzer@umich.edu"
      ],
      "author_institution": [
        "Department of Chemical Engineering, University of Michigan, Ann Arbor",
        "Department of Chemical Engineering, University of Michigan, Ann Arbor",
        "Department of Chemical Engineering, University of Michigan, Ann Arbor",
        "Department of Physics, University of Michigan, Ann Arbor",
        "Department of Chemical Engineering, University of Michigan, Ann Arbor",
        "Department of Materials Science and Engineering, University of Michigan, Ann Arbor",
        "Department of Physics, University of Michigan, Ann Arbor",
        "Biointerfaces Institute, University of Michigan, Ann Arbor"
      ],
      "copyright_holder": "Vyas Ramasubramani et al.",
      "author": [
        "Vyas Ramasubramani",
        "Carl S. Adorf",
        "Paul M. Dodd",
        "Bradley D. Dice",
        "Sharon C. Glotzer"
      ],
      "author_institution_map": {
        "Paul M. Dodd": [
          "Department of Chemical Engineering, University of Michigan, Ann Arbor"
        ],
        "Carl S. Adorf": [
          "Department of Chemical Engineering, University of Michigan, Ann Arbor"
        ],
        "Sharon C. Glotzer": [
          "Department of Chemical Engineering, University of Michigan, Ann Arbor",
          "Department of Materials Science and Engineering, University of Michigan, Ann Arbor",
          "Department of Physics, University of Michigan, Ann Arbor",
          "Biointerfaces Institute, University of Michigan, Ann Arbor"
        ],
        "Vyas Ramasubramani": [
          "Department of Chemical Engineering, University of Michigan, Ann Arbor"
        ],
        "Bradley D. Dice": [
          "Department of Physics, University of Michigan, Ann Arbor"
        ]
      },
      "bibliography": "paper",
      "authors": "Vyas Ramasubramani, Carl S. Adorf, Paul M. Dodd, Bradley D. Dice, Sharon C. Glotzer"
    },
    {
      "title": "Yaksh: Facilitating Learning by Doing",
      "paper_id": "yaksh",
      "abstract": [
        "Yaksh is a free and open-source online evaluation platform. At its core,\nYaksh focuses on problem-based learning and lets teachers create practice\nexercises and quizzes which are evaluated in real-time. A large array of\nquestion types like multiple choice, fill-in-the-blanks, assignment\nupload, and assertion or standard I/O based programming questions are\navailable. Yaksh supports Python, C, C++, Java, Bash, and Scilab\nprogramming languages. In addition, Yaksh allows teachers to create\nfull-blown courses with video and/or markdown text-based lessons. Yaksh is\ndesigned to be secure, easily deployable, and can scale-up to 500+ users\nsimultaneously."
      ],
      "page": {
        "stop": 167,
        "start": 160
      },
      "keywords": "",
      "video": "https://youtu.be/ngrfZIgrnW4",
      "doi": "10.25080/Majora-4af1f417-017",
      "pages": 8,
      "author_email": [
        "prabhu@aero.iitb.ac.in",
        "pratham920@gmail.com",
        "ankitrj.iitb@gmail.com",
        "aditya94palaparthy@gmail.com",
        "mahesh.p.gudi@gmail.com",
        "hardy\\_the1@yahoo.com"
      ],
      "author_institution": [
        "Department of Aerospace Engineering",
        "IIT Bombay, Mumbai, India",
        "FOSSEE IIT Bombay, Mumbai, India",
        "FOSSEE IIT Bombay, Mumbai, India",
        "FOSSEE IIT Bombay, Mumbai, India",
        "FOSSEE IIT Bombay, Mumbai, India",
        "FOSSEE IIT Bombay, Mumbai, India"
      ],
      "copyright_holder": "Prabhu Ramachandran et al.",
      "author": [
        "Prabhu Ramachandran",
        "Prathamesh Salunke",
        "Ankit Javalkar",
        "Aditya Palaparthy",
        "Mahesh Gudi",
        "Hardik Ghaghada"
      ],
      "author_institution_map": {
        "Ankit Javalkar": ["FOSSEE IIT Bombay, Mumbai, India"],
        "Aditya Palaparthy": ["FOSSEE IIT Bombay, Mumbai, India"],
        "Hardik Ghaghada": ["FOSSEE IIT Bombay, Mumbai, India"],
        "Prathamesh Salunke": ["FOSSEE IIT Bombay, Mumbai, India"],
        "Prabhu Ramachandran": [
          "Department of Aerospace Engineering",
          "IIT Bombay, Mumbai, India"
        ],
        "Mahesh Gudi": ["FOSSEE IIT Bombay, Mumbai, India"]
      },
      "bibliography": "",
      "authors": "Prabhu Ramachandran, Prathamesh Salunke, Ankit Javalkar, Aditya Palaparthy, Mahesh Gudi, Hardik Ghaghada"
    }
  ]
}
