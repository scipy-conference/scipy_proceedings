# Feel free to delete these first few references, which are specific to the template:

@article{Sherstinsky_2020,
   title={Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network},
   volume={404},
   ISSN={0167-2789},
   url={http://dx.doi.org/10.1016/j.physd.2019.132306},
   DOI={10.1016/j.physd.2019.132306},
   journal={Physica D: Nonlinear Phenomena},
   publisher={Elsevier BV},
   author={Sherstinsky, Alex},
   year={2020},
   month=mar, pages={132306} 
}

@misc{gu2023mamba,
      title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces}, 
      author={Albert Gu and Tri Dao},
      year={2023},
      eprint={2312.00752},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2312.00752}
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.1706.03762}
}

@misc{dao2023flashattention2,
      title={FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning}, 
      author={Tri Dao},
      year={2023},
      eprint={2307.08691},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2307.08691}
}

@misc{dao2022flashattention,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{gu2020hippo,
      title={HiPPO: Recurrent Memory with Optimal Polynomial Projections}, 
      author={Albert Gu and Tri Dao and Stefano Ermon and Atri Rudra and Christopher Re},
      year={2020},
      eprint={2008.07669},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2008.07669}
}

@misc{gu2022efficiently,
      title={Efficiently Modeling Long Sequences with Structured State Spaces}, 
      author={Albert Gu and Karan Goel and Christopher Ré},
      year={2022},
      eprint={2111.00396},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2111.00396}
}

@misc{gu2022parameterization,
      title={On the Parameterization and Initialization of Diagonal State Space Models}, 
      author={Albert Gu and Ankit Gupta and Karan Goel and Christopher Ré},
      year={2022},
      eprint={2206.11893},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2206.11893}
}

@misc{martin2018parallelizing,
      title={Parallelizing Linear Recurrent Neural Nets Over Sequence Length}, 
      author={Eric Martin and Chris Cundy},
      year={2018},
      eprint={1709.04057},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      DOI={https://doi.org/10.48550/arXiv.1709.04057}
}

@misc{lu2023structured,
      title={Structured State Space Models for In-Context Reinforcement Learning}, 
      author={Chris Lu and Yannick Schroecker and Albert Gu and Emilio Parisotto and Jakob Foerster and Satinder Singh and Feryal Behbahani},
      year={2023},
      eprint={2303.03982},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2303.03982}
}

@misc{peng2023rwkv,
      title={RWKV: Reinventing RNNs for the Transformer Era}, 
      author={Bo Peng and Eric Alcaide and Quentin Anthony and Alon Albalak and Samuel Arcadinho and Stella Biderman and Huanqi Cao and Xin Cheng and Michael Chung and Matteo Grella and Kranthi Kiran GV and Xuzheng He and Haowen Hou and Jiaju Lin and Przemyslaw Kazienko and Jan Kocon and Jiaming Kong and Bartlomiej Koptyra and Hayden Lau and Krishna Sri Ipsit Mantri and Ferdinand Mom and Atsushi Saito and Guangyu Song and Xiangru Tang and Bolun Wang and Johan S. Wind and Stanislaw Wozniak and Ruichong Zhang and Zhenyuan Zhang and Qihang Zhao and Peng Zhou and Qinghua Zhou and Jian Zhu and Rui-Jie Zhu},
      year={2023},
      eprint={2305.13048},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.2305.13048}
}

@misc{sun2023retentive,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.2307.08621}
}

@misc{elfwing2017sigmoidweighted,
      title={Sigmoid-Weighted Linear Units for Neural Network Function Approximation in Reinforcement Learning}, 
      author={Stefan Elfwing and Eiji Uchibe and Kenji Doya},
      year={2017},
      eprint={1702.03118},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.1702.03118}
}

@misc{oshea2015introduction,
      title={An Introduction to Convolutional Neural Networks}, 
      author={Keiron O'Shea and Ryan Nash},
      year={2015},
      eprint={1511.08458},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      DOI={https://doi.org/10.48550/arXiv.1511.08458}
}


@misc{lim2024parallelizing,
      title={Parallelizing non-linear sequential models over the sequence length}, 
      author={Yi Heng Lim and Qi Zhu and Joshua Selfridge and Muhammad Firmansyah Kasim},
      year={2024},
      eprint={2309.12252},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2309.12252}
}



@misc{ma2024umamba,
      title={U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation}, 
      author={Jun Ma and Feifei Li and Bo Wang},
      year={2024},
      eprint={2401.04722},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      DOI={https://doi.org/10.48550/arXiv.2401.04722}
}
@misc{zhu2024vision,
      title={Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model}, 
      author={Lianghui Zhu and Bencheng Liao and Qian Zhang and Xinlong Wang and Wenyu Liu and Xinggang Wang},
      year={2024},
      eprint={2401.09417},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      DOI={https://doi.org/10.48550/arXiv.2401.09417}
}

@misc{liu2024vmamba,
      title={VMamba: Visual State Space Model}, 
      author={Yue Liu and Yunjie Tian and Yuzhong Zhao and Hongtian Yu and Lingxi Xie and Yaowei Wang and Qixiang Ye and Yunfan Liu},
      year={2024},
      eprint={2401.10166},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      DOI={https://doi.org/10.48550/arXiv.2401.10166}
}
@misc{wang2024mambabyte,
      title={MambaByte: Token-free Selective State Space Model}, 
      author={Junxiong Wang and Tushaar Gangavarapu and Jing Nathan Yan and Alexander M. Rush},
      year={2024},
      eprint={2401.13660},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.2401.13660}
}

@misc{lieber2024jamba,
      title={Jamba: A Hybrid Transformer-Mamba Language Model}, 
      author={Opher Lieber and Barak Lenz and Hofit Bata and Gal Cohen and Jhonathan Osin and Itay Dalmedigos and Erez Safahi and Shaked Meirom and Yonatan Belinkov and Shai Shalev-Shwartz and Omri Abend and Raz Alon and Tomer Asida and Amir Bergman and Roman Glozman and Michael Gokhman and Avashalom Manevich and Nir Ratner and Noam Rozen and Erez Shwartz and Mor Zusman and Yoav Shoham},
      year={2024},
      eprint={2403.19887},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.2403.19887}
}
@misc{sun2023retentive,
      title={Retentive Network: A Successor to Transformer for Large Language Models}, 
      author={Yutao Sun and Li Dong and Shaohan Huang and Shuming Ma and Yuqing Xia and Jilong Xue and Jianyong Wang and Furu Wei},
      year={2023},
      eprint={2307.08621},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      DOI={https://doi.org/10.48550/arXiv.2307.08621}
}
@misc{de2024griffin,
      title={Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models}, 
      author={Soham De and Samuel L. Smith and Anushan Fernando and Aleksandar Botev and George Cristian-Muraru and Albert Gu and Ruba Haroun and Leonard Berrada and Yutian Chen and Srivatsan Srinivasan and Guillaume Desjardins and Arnaud Doucet and David Budden and Yee Whye Teh and Razvan Pascanu and Nando De Freitas and Caglar Gulcehre},
      year={2024},
      eprint={2402.19427},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2402.19427}
}
@misc{poli2023hyena,
      title={Hyena Hierarchy: Towards Larger Convolutional Language Models}, 
      author={Michael Poli and Stefano Massaroli and Eric Nguyen and Daniel Y. Fu and Tri Dao and Stephen Baccus and Yoshua Bengio and Stefano Ermon and Christopher Ré},
      year={2023},
      eprint={2302.10866},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      DOI={https://doi.org/10.48550/arXiv.2302.10866}
}
# These references may be helpful:
@inproceedings{jupyter,
  abstract  = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
  author    = {Kluyver, Thomas and Ragan-Kelley, Benjamin and Pérez, Fernando and Granger, Brian and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvain and Ivanov, Paul and Avila, Damián and Abdalla, Safia and Willing, Carol and {Jupyter development team}},
  editor    = {Loizides, Fernando and Scmidt, Birgit},
  location  = {Netherlands},
  publisher = {IOS Press},
  url       = {https://eprints.soton.ac.uk/403913/},
  booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
  year      = {2016},
  pages     = {87--90},
  title     = {Jupyter Notebooks - a publishing format for reproducible computational workflows},
}

@article{matplotlib,
  abstract     = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
  author       = {Hunter, J. D.},
  publisher    = {IEEE COMPUTER SOC},
  year         = {2007},
	doi          = {https://doi.org/10.1109/MCSE.2007.55},
  journal      = {Computing in Science \& Engineering},
  number       = {3},
  pages        = {90--95},
  title        = {Matplotlib: A 2D graphics environment},
  volume       = {9},
}

@article{numpy,
  author       = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  publisher    = {Springer Science and Business Media {LLC}},
  doi          = {https://doi.org/10.1038/s41586-020-2649-2},
  date         = {2020-09},
  year         = {2020},
  journal      = {Nature},
  number       = {7825},
  pages        = {357--362},
  title        = {Array programming with {NumPy}},
  volume       = {585},
}

@misc{pandas1,
  author    = {{The Pandas Development Team}},
  title     = {pandas-dev/pandas: Pandas},
  month     = feb,
  year      = {2020},
  publisher = {Zenodo},
  version   = {latest},
  url       = {https://doi.org/10.5281/zenodo.3509134},
}

@inproceedings{pandas2,
  author    = {Wes McKinney},
  title     = {{D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython},
  booktitle = {{P}roceedings of the 9th {P}ython in {S}cience {C}onference},
  pages     = {56 - 61},
  year      = {2010},
  editor    = {{S}t\'efan van der {W}alt and {J}arrod {M}illman},
	doi       = {https://doi.org/10.25080/Majora-92bf1922-00a},
}

@article{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
	doi     = {https://doi.org/10.1038/s41592-019-0686-2},
}

@article{sklearn1,
  author       = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year         = {2011},
  journal      = {Journal of Machine Learning Research},
  pages        = {2825--2830},
  title        = {Scikit-learn: Machine Learning in {P}ython},
  volume       = {12},
}

@inproceedings{sklearn2,
  author    = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and VanderPlas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Gaël},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages     = {108--122},
  title     = {{API} design for machine learning software: experiences from the scikit-learn project},
}
@misc{mamba_github,
  author = {{Albert Gu, Tri Dao}},
  title  = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  year   = {2024},
  url    = {https://github.com/state-spaces/mamba},
  note   = {}
}
@misc{mamba_s4,
  author = {{Albert Gu, Karan Goel, Christopher Ré}},
  title  = {Structured State Spaces for Sequence Modeling},
  year   = {31 Oct 2021},
  url    = {https://github.com/state-spaces/s4},
  note   = {}
}
@misc{transformer_py,
  author = {{Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin}},
  title  = {Transformer model from Attention Is All You Need},
  year   = {12 Jun 2017},
  url    = {https://github.com/tensorflow/tensor2tensor},
  note   = {}
}