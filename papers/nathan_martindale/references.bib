@inproceedings{jupyter,
  abstract  = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
  author    = {Kluyver, Thomas and Ragan-Kelley, Benjamin and Pérez, Fernando and Granger, Brian and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvain and Ivanov, Paul and Avila, Damián and Abdalla, Safia and Willing, Carol and {Jupyter Development Team}},
  editor    = {Loizides, Fernando and Scmidt, Birgit},
  location  = {Netherlands},
  publisher = {IOS Press},
  url       = {https://eprints.soton.ac.uk/403913/},
  booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
  year      = {2016},
  pages     = {87--90},
  title     = {Jupyter Notebooks - A Publishing Format for Reproducible Computational Workflows},
}


@inproceedings{shneidermanEyesHaveIt1996,
	title = {The eyes have it: A task by data type taxonomy for information visualizations},
	shorttitle = {The eyes have it},
	url = {https://ieeexplore.ieee.org/abstract/document/545307},
	doi = {10.1109/VL.1996.545307},
	abstract = {A useful starting point for designing advanced graphical user interfaces is the visual information seeking Mantra: overview first, zoom and filter, then details on demand. But this is only a starting point in trying to understand the rich and varied set of information visualizations that have been proposed in recent years. The paper offers a task by data type taxonomy with seven data types (one, two, three dimensional data, temporal and multi dimensional data, and tree and network data) and seven tasks (overview, zoom, filter, details-on-demand, relate, history, and extracts).},
	urldate = {2023-12-04},
	booktitle = {Proceedings 1996 {IEEE} {Symposium} on {Visual} {Languages}},
	author = {Shneiderman, B.},
	month = sep,
	year = {1996},
	note = {ISSN: 1049-2615},
	keywords = {ToRead},
	pages = {336--343},
	file = {IEEE Xplore Abstract Record:/home/81n/Zotero/storage/46XEVFA4/545307.html:text/html;IEEE Xplore Full Text PDF:/home/81n/Zotero/storage/CEWS7NQL/Shneiderman - 1996 - The eyes have it a task by data type taxonomy for.pdf:application/pdf},
}

@article{lucianiDetailsFirstShowContext2019,
	title = {Details-{First}, {Show} {Context}, {Overview} {Last}: {Supporting} {Exploration} of {Viscous} {Fingers} in {Large}-{Scale} {Ensemble} {Simulations}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {Details-{First}, {Show} {Context}, {Overview} {Last}},
	url = {https://ieeexplore.ieee.org/abstract/document/8440850},
	doi = {10.1109/TVCG.2018.2864849},
	abstract = {Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: “Overview first, zoom and filter, then details on demand”. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.},
	number = {1},
	urldate = {2023-12-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Luciani, Timothy and Burks, Andrew and Sugiyama, Cassiano and Komperda, Jonathan and Marai, G. Elisabeta},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {ToRead},
	pages = {1225--1235},
	file = {IEEE Xplore Abstract Record:/home/81n/Zotero/storage/BAJ97DJQ/8440850.html:text/html;IEEE Xplore Full Text PDF:/home/81n/Zotero/storage/4D3XCSLA/Luciani et al. - 2019 - Details-First, Show Context, Overview Last Suppor.pdf:application/pdf},
}

@inproceedings{barlowtwins,
	title = {Barlow {Twins}: {Self}-{supervised} {learning} via {redundancy} {reduction}},
	shorttitle = {Barlow {Twins}},
	url = {https://proceedings.mlr.press/v139/zbontar21a.html},
	abstract = {Self-supervised learning (SSL) is rapidly closing the gap with supervised methods on large computer vision benchmarks. A successful approach to SSL is to learn embeddings which are invariant to distortions of the input sample. However, a recurring issue with this approach is the existence of trivial constant solutions. Most current methods avoid such solutions by careful implementation details. We propose an objective function that naturally avoids collapse by measuring the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of a sample, and making it as close to the identity matrix as possible. This causes the embedding vectors of distorted versions of a sample to be similar, while minimizing the redundancy between the components of these vectors. The method is called Barlow Twins, owing to neuroscientist H. Barlow’s redundancy-reduction principle applied to a pair of identical networks. Barlow Twins does not require large batches nor asymmetry between the network twins such as a predictor network, gradient stopping, or a moving average on the weight updates. Intriguingly it benefits from very high-dimensional output vectors. Barlow Twins outperforms previous methods on ImageNet for semi-supervised classification in the low-data regime, and is on par with current state of the art for ImageNet classification with a linear classifier head, and for transfer tasks of classification and object detection.},
	language = {en},
	urldate = {2024-05-14},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, Stephane},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	pages = {12310--12320},
}

@misc{ipywidgets,
	title = {jupyter-widgets/ipywidgets},
	copyright = {BSD-3-Clause},
	url = {https://github.com/jupyter-widgets/ipywidgets},
	abstract = {Interactive Widgets for the Jupyter Notebook},
	urldate = {2024-05-14},
	author = {{Jupyter Widgets}},
	year = {2015},
    note = {Accessed 14 May. 2024},
}

@misc{LowLevelWidget,
    author = {{Jupyter Widgets}},
	title = {Low {Level} {Widget} {Explanation} — {Jupyter} {Widgets} 8.1.2 documentation},
	url = {https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Low%20Level.html},
	urldate = {2024-05-14},
    year = {2024},
    note = {Accessed 14 May. 2024},
}

@misc{ipywidgets_cookiecutter,
    author = {{Jupyter Widgets}},
	title = {jupyter-widgets/widget-cookiecutter: {A} cookiecutter template for creating a custom {Jupyter} widget project.},
	url = {https://github.com/jupyter-widgets/widget-cookiecutter},
	urldate = {2024-05-14},
    year = {2024},
    note = {Accessed 14 May. 2024},
}

@misc{plotly,
    author = {{Plotly, Inc.}},
	title = {plotly/plotly.py: {The} interactive graphing library for {Python}},
	url = {https://github.com/plotly/plotly.py},
	urldate = {2024-05-14},
    year = {2019},
    NOTE: = {Accessed 14 May. 2024},
}

@misc{mpld3,
	title = {mpld3/mpld3},
	copyright = {BSD-3-Clause},
	url = {https://github.com/mpld3/mpld3},
	abstract = {An interactive data visualization tool which brings matplotlib graphics to the browser using D3.},
	urldate = {2024-05-14},
	publisher = {mpld3},
	author = {VanderPlas, Jake},
	year = {2013},
	note = {Accessed 14 May. 2024},
}

@article{altair,
	title = {Altair: {Interactive} {Statistical} {Visualizations} for {Python}},
	volume = {3},
	issn = {2475-9066},
	shorttitle = {Altair},
	url = {https://joss.theoj.org/papers/10.21105/joss.01057},
	doi = {10.21105/joss.01057},
	abstract = {VanderPlas et al., (2018). Altair: Interactive statistical visualizations for Python. Journal of Open Source Software, 3(32), 1057, https://doi.org/10.21105/joss.01057},
	language = {en},
	number = {32},
	urldate = {2024-05-14},
	journal = {Journal of Open Source Software},
	author = {VanderPlas, Jacob and Granger, Brian E. and Heer, Jeffrey and Moritz, Dominik and Wongsuphasawat, Kanit and Satyanarayan, Arvind and Lees, Eitan and Timofeev, Ilia and Welsh, Ben and Sievert, Scott},
	month = dec,
	year = {2018},
	pages = {1057},
}

@misc{bqplot,
    author = {{The BQplot Project}},
	title = {bqplot/bqplot},
	copyright = {Apache-2.0},
	url = {https://github.com/bqplot/bqplot},
	abstract = {Plotting library for IPython/Jupyter notebooks},
	urldate = {2024-05-14},
	year = {2015},
	note = {Accessed 14 May. 2024},
}

@misc{pythreejs,
    author = {{Jupyter Widgets}},
	title = {jupyter-widgets/pythreejs},
	url = {https://github.com/jupyter-widgets/pythreejs},
	abstract = {A Jupyter - Three.js bridge},
	urldate = {2024-05-14},
	publisher = {Jupyter Widgets},
	year = {2024},
	note = {Accessed 14 May. 2024},
}

@misc{ipyleaflet,
    author = {{Jupyter Widgets}},
	title = {jupyter-widgets/ipyleaflet},
	copyright = {MIT},
	url = {https://github.com/jupyter-widgets/ipyleaflet},
	abstract = {A Jupyter - Leaflet.js bridge},
	urldate = {2024-05-14},
	year = {2024},
	note = {Accessed 14 May. 2024},
}

@misc{ipycytoscape,
	title = {cytoscape/ipycytoscape},
	copyright = {BSD-3-Clause},
	url = {https://github.com/cytoscape/ipycytoscape},
	abstract = {A Cytoscape Jupyter widget},
	urldate = {2024-05-14},
	publisher = {Cytoscape Consortium},
	author = {Meireles, Mariana},
	year = {2020},
	note = {Accessed 14 May. 2024},
}

@misc{solara,
    author = {Maarten A. Breddels},
	title = {widgetti/solara},
	copyright = {MIT},
	url = {https://github.com/widgetti/solara},
	abstract = {A Pure Python, React-style Framework for Scaling Your Jupyter and Web Apps},
	urldate = {2024-05-14},
	year = {2022},
	note = {Accessed: 14 May. 2024},
}

@misc{ipyreact,
    author = {Maarten A. Breddels},
	title = {widgetti/ipyreact},
	copyright = {BSD-3-Clause},
	url = {https://github.com/widgetti/ipyreact},
	abstract = {React for ipywidgets that just works. No webpack, no npm, no hassle},
	urldate = {2024-05-14},
	year = {2023},
	note = {Accessed 14 May. 2024},
}

@misc{ipyvuetify,
    author = {Mario Buikhuizen},
	title = {widgetti/ipyvuetify: {Jupyter} widgets based on vuetify {UI} components},
	url = {https://github.com/widgetti/ipyvuetify},
	urldate = {2024-05-14},
    year = {2019},
    note = {Accessed 14 May. 2024},
}

@misc{traitlets,
    author = {{IPython Development Team}},
	title = {ipython/traitlets},
	copyright = {BSD-3-Clause},
	url = {https://github.com/ipython/traitlets},
	abstract = {A lightweight Traits like module},
	urldate = {2024-05-14},
	year = {2001},
	note = {Accessed 14 May. 2024},
}

@misc{materialdesign,
    author = {Google},
    title = {Material Design},
    year = {2014},
    url = {https://material.io},
    note = {Accessed 26 July, 2024}, 
}
    
