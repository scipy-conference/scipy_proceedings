
@incollection{asgeirssonExploringPotentialEnergy2018,
  ids = {asgeirssonExploringPotentialEnergy2018a},
  title = {Exploring {{Potential Energy Surfaces}} with {{Saddle Point Searches}}},
  booktitle = {Handbook of {{Materials Modeling}}},
  author = {Ásgeirsson, Vilhjálmur and Jónsson, Hannes},
  editor = {Andreoni, Wanda and Yip, Sidney},
  date = {2018},
  pages = {1--26},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-42913-7_28-1},
  url = {http://link.springer.com/10.1007/978-3-319-42913-7_28-1},
  urldate = {2020-03-02},
  abstract = {The energy surface of an atomic scale representation of a material contains the essential information needed to determine the structure and time evolution of the system at a given temperature. Local minima on the surface represent (meta)stable states of the system, while first-order saddle points characterize the mechanisms of transitions between states. While many well-known methods make it relatively easy to find local minima, the identification of saddle points is more challenging. In this chapter, methods for finding saddle points are discussed as well as applications to materials simulations. Both doubly constrained search methods, where the final and the initial state minima are specified, and singly constrained search methods, where only the initial state is specified, are discussed. The focus is on a classical description of the atom coordinates, but saddle points corresponding to quantum mechanical tunneling are also mentioned. An extension to magnetic systems where the energy surface depends on the orientation of the magnetic vectors is sketched.},
  isbn = {978-3-319-42913-7},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/GR7DZTQV/Ásgeirsson and Jónsson - 2018 - Exploring Potential Energy Surfaces with Saddle Po.pdf;/Users/rgoswami/Zotero default/storage/VD7S25DI/Ásgeirsson and Jónsson - 2018 - Exploring Potential Energy Surfaces with Saddle Po.pdf}
}

@unpublished{blumRecoveringBiasedData2019,
  title = {Recovering from {{Biased Data}}: {{Can Fairness Constraints Improve Accuracy}}?},
  shorttitle = {Recovering from {{Biased Data}}},
  author = {Blum, Avrim and Stangl, Kevin},
  date = {2019-12-02},
  eprint = {1912.01094},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1912.01094},
  urldate = {2020-06-16},
  abstract = {Multiple fairness constraints have been proposed in the literature, motivated by a range of concerns about how demographic groups might be treated unfairly by machine learning classifiers. In this work we consider a different motivation; learning from biased training data. We posit several ways in which training data may be biased, including having a more noisy or negatively biased labeling process on members of a disadvantaged group, or a decreased prevalence of positive or negative examples from the disadvantaged group, or both. Given such biased training data, Empirical Risk Minimization (ERM) may produce a classifier that not only is biased but also has suboptimal accuracy on the true data distribution. We examine the ability of fairness-constrained ERM to correct this problem. In particular, we find that the Equal Opportunity fairness constraint (Hardt, Price, and Srebro 2016) combined with ERM will provably recover the Bayes Optimal Classifier under a range of bias models. We also consider other recovery methods including reweighting the training data, Equalized Odds, and Demographic Parity. These theoretical results provide additional motivation for considering fairness interventions even if an actor cares primarily about accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/rgoswami/Zotero default/storage/RCZXGGKK/Blum_Stangl_2019_Recovering from Biased Data.pdf;/Users/rgoswami/Zotero default/storage/SHPGB78N/1912.html}
}

@software{communityTuringWayHandbook2019,
  title = {The {{Turing Way}}: {{A Handbook}} for {{Reproducible Data Science}}},
  shorttitle = {The {{Turing Way}}},
  author = {Community, The Turing Way and Arnold, Becky and Bowler, Louise and Gibson, Sarah and Herterich, Patricia and Higman, Rosie and Krystalli, Anna and Morley, Alexander and O'Reilly, Martin and Whitaker, Kirstie},
  date = {2019-03-25},
  url = {https://doi.org/10.5281/zenodo.3233986},
  urldate = {2020-09-20},
  abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists.{$<$}em{$>$} {$<$}/em{$><$}em{$>$}The Turing Way{$<$}/em{$>$} is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. {$<$}strong{$>$}Release log{$<$}/strong{$>$} {$<$}strong{$>$}v0.0.4:{$<$}/strong{$>$} Continuous integration chapter merged to master. {$<$}strong{$>$}v0.0.3:{$<$}/strong{$>$} Reproducible environments chapter merged to master. {$<$}strong{$>$}v0.0.2:{$<$}/strong{$>$} Version control chapter merged to master. {$<$}strong{$>$}v0.0.1: {$<$}/strong{$>$}Reproducibility chapter merged to master.},
  organization = {{Zenodo}},
  version = {v0.0.4},
  keywords = {archived},
  annotation = {00000}
}

@article{deComparingMoleculesSolids2016,
  title = {Comparing Molecules and Solids across Structural and Alchemical Space},
  author = {De, Sandip and Bartók, Albert P. and Csányi, Gábor and Ceriotti, Michele},
  date = {2016-05-18},
  journaltitle = {Physical Chemistry Chemical Physics},
  shortjournal = {Phys. Chem. Chem. Phys.},
  volume = {18},
  number = {20},
  pages = {13754--13769},
  publisher = {{The Royal Society of Chemistry; http://web.archive.org/web/20200619022204/https://pubs.rsc.org/en/content/articlelanding/2016/cp/c6cp00415f}},
  issn = {1463-9084},
  doi = {10.1039/C6CP00415F},
  url = {10.1039/C6CP00415F},
  urldate = {2020-06-19},
  abstract = {Evaluating the (dis)similarity of crystalline, disordered and molecular compounds is a critical step in the development of algorithms to navigate automatically the configuration space of complex materials. For instance, a structural similarity metric is crucial for classifying structures, searching chemical space for better compounds and materials, and driving the next generation of machine-learning techniques for predicting the stability and properties of molecules and materials. In the last few years several strategies have been designed to compare atomic coordination environments. In particular, the smooth overlap of atomic positions (SOAPs) has emerged as an elegant framework to obtain translation, rotation and permutation-invariant descriptors of groups of atoms, underlying the development of various classes of machine-learned inter-atomic potentials. Here we discuss how one can combine such local descriptors using a regularized entropy match (REMatch) approach to describe the similarity of both whole molecular and bulk periodic structures, introducing powerful metrics that enable the navigation of alchemical and structural complexities within a unified framework. Furthermore, using this kernel and a ridge regression method we can predict atomization energies for a database of small organic molecules with a mean absolute error below 1 kcal mol−1, reaching an important milestone in the application of machine-learning techniques for the evaluation of molecular properties.},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/A4TQQSCM/De et al_2016_Comparing molecules and solids across structural and alchemical space.pdf;/Users/rgoswami/Zotero default/storage/K7KEH9D2/De et al. - 2016 - Comparing molecules and solids across structural a.pdf;/Users/rgoswami/Zotero default/storage/3LWXITHF/c6cp00415f.html}
}

@article{dralQuantumChemistryAge2020,
  title = {Quantum {{Chemistry}} in the {{Age}} of {{Machine Learning}}},
  author = {Dral, Pavlo O.},
  date = {2020-03-19},
  journaltitle = {The Journal of Physical Chemistry Letters},
  shortjournal = {J. Phys. Chem. Lett.},
  volume = {11},
  number = {6},
  pages = {2336--2347},
  publisher = {{American Chemical Society; http://web.archive.org/web/20200622155222/https://pubs.acs.org/doi/10.1021/acs.jpclett.9b03664}},
  doi = {10.1021/acs.jpclett.9b03664},
  url = {10.1021/acs.jpclett.9b03664},
  urldate = {2020-06-22},
  abstract = {As the quantum chemistry (QC) community embraces machine learning (ML), the number of new methods and applications based on the combination of QC and ML is surging. In this Perspective, a view of the current state of affairs in this new and exciting research field is offered, challenges of using machine learning in quantum chemistry applications are described, and potential future developments are outlined. Specifically, examples of how machine learning is used to improve the accuracy and accelerate quantum chemical research are shown. Generalization and classification of existing techniques are provided to ease the navigation in the sea of literature and to guide researchers entering the field. The emphasis of this Perspective is on supervised machine learning.},
  file = {/Users/rgoswami/Zotero default/storage/4TFI5JY4/10.1021@acs.jpclett.9b03664.pdf;/Users/rgoswami/Zotero default/storage/K2ELV2TI/Dral_2020_Quantum Chemistry in the Age of Machine Learning.pdf;/Users/rgoswami/Zotero default/storage/EFMJR8A6/acs.jpclett.html}
}

@unpublished{engstromIdentifyingStatisticalBias2020,
  title = {Identifying {{Statistical Bias}} in {{Dataset Replication}}},
  author = {Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Steinhardt, Jacob and Madry, Aleksander},
  date = {2020-05-19},
  eprint = {2005.09619},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2005.09619},
  urldate = {2020-06-09},
  abstract = {Dataset replication is a useful tool for assessing whether improvements in test accuracy on a specific benchmark correspond to improvements in models' ability to generalize reliably. In this work, we present unintuitive yet significant ways in which standard approaches to dataset replication introduce statistical bias, skewing the resulting observations. We study ImageNet-v2, a replication of the ImageNet dataset on which models exhibit a significant (11-14\%) drop in accuracy, even after controlling for a standard human-in-the-loop measure of data quality. We show that after correcting for the identified statistical bias, only an estimated \$3.6\textbackslash\% \textbackslash pm 1.5\textbackslash\%\$ of the original \$11.7\textbackslash\% \textbackslash pm 1.0\textbackslash\%\$ accuracy drop remains unaccounted for. We conclude with concrete recommendations for recognizing and avoiding bias in dataset replication. Code for our study is publicly available at http://github.com/MadryLab/dataset-replication-analysis .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/rgoswami/Zotero default/storage/EYRXM3GA/Engstrom et al_2020_Identifying Statistical Bias in Dataset Replication.pdf;/Users/rgoswami/Zotero default/storage/FQISHWU3/2005.html}
}

@article{gaoMachineLearningCorrection2016,
  title = {A Machine Learning Correction for {{DFT}} Non-Covalent Interactions Based on the {{S22}}, {{S66}} and {{X40}} Benchmark Databases},
  author = {Gao, Ting and Li, Hongzhi and Li, Wenze and Li, Lin and Fang, Chao and Li, Hui and Hu, LiHong and Lu, Yinghua and Su, Zhong-Min},
  date = {2016-05-03},
  journaltitle = {Journal of Cheminformatics},
  shortjournal = {Journal of Cheminformatics},
  volume = {8},
  number = {1},
  pages = {24},
  issn = {1758-2946},
  doi = {10.1186/s13321-016-0133-7},
  url = {https://doi.org/10.1186/s13321-016-0133-7},
  urldate = {2020-12-08},
  abstract = {Non-covalent interactions (NCIs) play critical roles in supramolecular chemistries; however, they are difficult to measure. Currently, reliable computational methods are being pursued to meet this challenge, but the accuracy of calculations based on low levels of theory is not satisfactory and calculations based on high levels of theory are often too costly. Accordingly, to reduce the cost and increase the accuracy of low-level theoretical calculations to describe NCIs, an efficient approach is proposed to correct NCI calculations based on the benchmark databases S22, S66 and X40 (Hobza in Acc Chem Rev 45: 663–672, 2012; Řezáč et al. in J Chem Theory Comput 8:4285, 2012).},
  keywords = {Computational accuracy,Density functional theory,Feature selection,Machine learning correction,Non-covalent interactions},
  file = {/Users/rgoswami/Zotero default/storage/SVNEIGX2/Gao et al_2016_A machine learning correction for DFT non-covalent interactions based on the.pdf}
}

@unpublished{hojaQM7XComprehensiveDataset2020,
  title = {{{QM7-X}}: {{A}} Comprehensive Dataset of Quantum-Mechanical Properties Spanning the Chemical Space of Small Organic Molecules},
  shorttitle = {{{QM7-X}}},
  author = {Hoja, Johannes and Sandonas, Leonardo Medrano and Ernst, Brian G. and Vazquez-Mayagoitia, Alvaro and DiStasio Jr., Robert A. and Tkatchenko, Alexandre},
  date = {2020-06-26},
  eprint = {2006.15139},
  eprinttype = {arxiv},
  primaryclass = {physics},
  url = {http://arxiv.org/abs/2006.15139},
  urldate = {2020-09-28},
  abstract = {We introduce QM7-X, a comprehensive dataset of 42 physicochemical properties for \$\textbackslash approx\$ 4.2 M equilibrium and non-equilibrium structures of small organic molecules with up to seven non-hydrogen (C, N, O, S, Cl) atoms. To span this fundamentally important region of chemical compound space (CCS), QM7-X includes an exhaustive sampling of (meta-)stable equilibrium structures - comprised of constitutional/structural isomers and stereoisomers, e.g., enantiomers and diastereomers (including cis-/trans- and conformational isomers) - as well as 100 non-equilibrium structural variations thereof to reach a total of \$\textbackslash approx\$ 4.2 M molecular structures. Computed at the tightly converged quantum-mechanical PBE0+MBD level of theory, QM7-X contains global (molecular) and local (atom-in-a-molecule) properties ranging from ground state quantities (such as atomization energies and dipole moments) to response quantities (such as polarizability tensors and dispersion coefficients). By providing a systematic, extensive, and tightly-converged dataset of quantum-mechanically computed physicochemical properties, we expect that QM7-X will play a critical role in the development of next-generation machine-learning based models for exploring greater swaths of CCS and performing in silico design of molecules with targeted properties.},
  archiveprefix = {arXiv},
  keywords = {Physics - Chemical Physics},
  file = {/Users/rgoswami/Zotero default/storage/G4L5SVG8/Hoja et al_2020_QM7-X.pdf;/Users/rgoswami/Zotero default/storage/95CSWL79/2006.html}
}

@unpublished{huberAiiDAScalableComputational2020,
  title = {{{AiiDA}} 1.0, a Scalable Computational Infrastructure for Automated Reproducible Workflows and Data Provenance},
  author = {Huber, Sebastiaan P. and Zoupanos, Spyros and Uhrin, Martin and Talirz, Leopold and Kahle, Leonid and Häuselmann, Rico and Gresch, Dominik and Müller, Tiziano and Yakutovich, Aliaksandr V. and Andersen, Casper W. and Ramirez, Francisco F. and Adorf, Carl S. and Gargiulo, Fernando and Kumbhar, Snehal and Passaro, Elsa and Johnston, Conrad and Merkys, Andrius and Cepellotti, Andrea and Mounet, Nicolas and Marzari, Nicola and Kozinsky, Boris and Pizzi, Giovanni},
  date = {2020-03-24},
  eprint = {2003.12476},
  eprinttype = {arxiv},
  primaryclass = {cond-mat},
  url = {http://arxiv.org/abs/2003.12476},
  urldate = {2020-07-07},
  abstract = {The ever-growing availability of computing power and the sustained development of advanced computational methods have contributed much to recent scientific progress. These developments present new challenges driven by the sheer amount of calculations and data to manage. Next-generation exascale supercomputers will harden these challenges, such that automated and scalable solutions become crucial. In recent years, we have been developing AiiDA (http://www.aiida.net), a robust open-source high-throughput infrastructure addressing the challenges arising from the needs of automated workflow management and data provenance recording. Here, we introduce developments and capabilities required to reach sustained performance, with AiiDA supporting throughputs of tens of thousands processes/hour, while automatically preserving and storing the full data provenance in a relational database making it queryable and traversable, thus enabling high-performance data analytics. AiiDA's workflow language provides advanced automation, error handling features and a flexible plugin model to allow interfacing with any simulation software. The associated plugin registry enables seamless sharing of extensions, empowering a vibrant user community dedicated to making simulations more robust, user-friendly and reproducible.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Condensed Matter - Materials Science},
  file = {/Users/rgoswami/Zotero default/storage/PG9P9FQI/Huber et al_2020_AiiDA 1.pdf;/Users/rgoswami/Zotero default/storage/QHPP3RK4/2003.html}
}

@article{kohnNobelLectureElectronic1999,
  title = {Nobel {{Lecture}}: {{Electronic}} Structure of Matter---Wave Functions and Density Functionals},
  shorttitle = {Nobel {{Lecture}}},
  author = {Kohn, W.},
  date = {1999-10-01},
  journaltitle = {Reviews of Modern Physics},
  shortjournal = {Rev. Mod. Phys.},
  volume = {71},
  number = {5},
  pages = {1253--1266},
  publisher = {{American Physical Society}},
  doi = {10.1103/RevModPhys.71.1253},
  url = {https://link.aps.org/doi/10.1103/RevModPhys.71.1253},
  urldate = {2020-03-20},
  file = {/Users/rgoswami/Zotero default/storage/2IKK8VWA/Kohn - 1999 - Nobel Lecture Electronic structure of matter---wa.pdf;/Users/rgoswami/Zotero default/storage/X9EK4VMD/Kohn - 1999 - Nobel Lecture Electronic structure of matter—wave.pdf;/Users/rgoswami/Zotero default/storage/E7E9ZDUH/RevModPhys.71.html}
}

@article{kolosImprovedTheoreticalGround1968,
  title = {Improved {{Theoretical Ground}}‐{{State Energy}} of the {{Hydrogen Molecule}}},
  author = {Kolos, W. and Wolniewicz, L.},
  date = {1968-07-01},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {49},
  number = {1},
  pages = {404--410},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.1669836},
  url = {10.1063/1.1669836},
  urldate = {2020-11-17},
  file = {/Users/rgoswami/Zotero default/storage/WAWXNRA5/Kolos_Wolniewicz_1968_Improved Theoretical Ground‐State Energy of the Hydrogen Molecule.pdf}
}

@article{larsenAtomicSimulationEnvironment2017,
  title = {The Atomic Simulation Environment—a {{Python}} Library for Working with Atoms},
  author = {Larsen, Ask Hjorth and Mortensen, Jens Jørgen and Blomqvist, Jakob and Castelli, Ivano E. and Christensen, Rune and Du\textbackslash lak, Marcin and Friis, Jesper and Groves, Michael N. and Hammer, Bjørk and Hargus, Cory and Hermes, Eric D. and Jennings, Paul C. and Jensen, Peter Bjerre and Kermode, James and Kitchin, John R. and Kolsbjerg, Esben Leonhard and Kubal, Joseph and Kaasbjerg, Kristen and Lysgaard, Steen and Maronsson, Jón Bergmann and Maxson, Tristan and Olsen, Thomas and Pastewka, Lars and Peterson, Andrew and Rostgaard, Carsten and Schiøtz, Jakob and Schütt, Ole and Strange, Mikkel and Thygesen, Kristian S. and Vegge, Tejs and Vilhelmsen, Lasse and Walter, Michael and Zeng, Zhenhua and Jacobsen, Karsten W.},
  date = {2017-06},
  journaltitle = {Journal of Physics: Condensed Matter},
  shortjournal = {J. Phys.: Condens. Matter},
  volume = {29},
  number = {27},
  pages = {273002},
  issn = {0953-8984},
  doi = {10.1088/1361-648X/aa680e},
  url = {https://doi.org/10.1088%2F1361-648x%2Faa680e},
  urldate = {2020-01-24},
  abstract = {The atomic simulation environment (ASE) is a software package written in the Python programming language with the aim of setting up, steering, and analyzing atomistic simulations. In ASE, tasks are fully scripted in Python. The powerful syntax of Python combined with the NumPy array library make it possible to perform very complex simulation tasks. For example, a sequence of calculations may be performed with the use of a simple ‘for-loop’ construction. Calculations of energy, forces, stresses and other quantities are performed through interfaces to many external electronic structure codes or force fields using a uniform interface. On top of this calculator interface, ASE provides modules for performing many standard simulation tasks such as structure optimization, molecular dynamics, handling of constraints and performing nudged elastic band calculations.},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/WWJS2GRV/Larsen et al. - 2017 - The atomic simulation environment—a Python library.pdf;/Users/rgoswami/Zotero default/storage/3XXP8TTY/larsen2017.html}
}

@article{meyerMachineLearningComputational2019,
  title = {Machine {{Learning}} in {{Computational Chemistry}}: {{An Evaluation}} of {{Method Performance}} for {{Nudged Elastic Band Calculations}}},
  shorttitle = {Machine {{Learning}} in {{Computational Chemistry}}},
  author = {Meyer, Ralf and Schmuck, Klemens S. and Hauser, Andreas W.},
  date = {2019-11-12},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {15},
  number = {11},
  pages = {6513--6523},
  publisher = {{American Chemical Society}},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.9b00708},
  url = {https://doi.org/10.1021/acs.jctc.9b00708},
  urldate = {2020-03-29},
  abstract = {The localization of transition states and the calculation of reaction pathways are routine tasks of computational chemists but often very CPU-intense problems, in particular for large systems. The standard algorithm for this purpose is the nudged elastic band method, but it has become obvious that an “intelligent” selection of points to be evaluated on the potential energy surface can improve its convergence significantly. This article summarizes, compares, and extends known strategies that have been heavily inspired by the machine learning developments of recent years. It presents advantages and disadvantages and provides an unbiased comparison of neural network based approaches, Gaussian process regression in Cartesian coordinates, and Gaussian approximation potentials. We test their performance on two example reactions, the ethane rotation and the activation of carbon dioxide on a metal catalyst, and provide a clear ranking in terms of usability for future implementations.},
  keywords = {\#nosource}
}

@article{millmanPythonScientistsEngineers2011,
  title = {Python for {{Scientists}} and {{Engineers}}},
  author = {Millman, K. J. and Aivazis, M.},
  date = {2011-03},
  journaltitle = {Computing in Science Engineering},
  volume = {13},
  number = {2},
  pages = {9--12},
  doi = {10/dc343g},
  abstract = {Python has arguably become the de facto standard for exploratory, interactive, and computation-driven scientific research. This issue discusses Python's advantages for scientific research and presents several of the core Python libraries and tools used in scientific research.},
  keywords = {\#nosource,Computer languages,interactive research,Numerical models,Programming,Programming languages,Python,Python libraries,Python tools,Scientific computing,Special issues and sections}
}

@article{neeseORCAProgramSystem2012,
  title = {The {{ORCA}} Program System},
  author = {Neese, Frank},
  date = {2012},
  journaltitle = {WIREs Computational Molecular Science},
  volume = {2},
  number = {1},
  pages = {73--78},
  issn = {1759-0884},
  doi = {10.1002/wcms.81},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.81},
  urldate = {2022-06-28},
  abstract = {ORCA is a general-purpose quantum chemistry program package that features virtually all modern electronic structure methods (density functional theory, many-body perturbation and coupled cluster theories, and multireference and semiempirical methods). It is designed with the aim of generality, extendibility, efficiency, and user friendliness. Its main field of application is larger molecules, transition metal complexes, and their spectroscopic properties. ORCA uses standard Gaussian basis functions and is fully parallelized. The article provides an overview of its current possibilities and documents its efficiency. © 2011 John Wiley \& Sons, Ltd. This article is categorized under: Software {$>$} Quantum Chemistry},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.81},
  file = {/Users/rgoswami/Zotero default/storage/Y5A33DE8/Neese_2012_The ORCA program system.pdf}
}

@article{neeseORCAQuantumChemistry2020,
  title = {The {{ORCA}} Quantum Chemistry Program Package},
  author = {Neese, Frank and Wennmohs, Frank and Becker, Ute and Riplinger, Christoph},
  date = {2020-06-12},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {152},
  number = {22},
  pages = {224108},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/5.0004608},
  url = {https://aip.scitation.org/doi/10.1063/5.0004608},
  urldate = {2020-11-28},
  abstract = {In this contribution to the special software-centered issue, the ORCA program package is described. We start with a short historical perspective of how the project began and go on to discuss its current feature set. ORCA has grown into a rather comprehensive general-purpose package for theoretical research in all areas of chemistry and many neighboring disciplines such as materials sciences and biochemistry. ORCA features density functional theory, a range of wavefunction based correlation methods, semi-empirical methods, and even force-field methods. A range of solvation and embedding models is featured as well as a complete intrinsic to ORCA quantum mechanics/molecular mechanics engine. A specialty of ORCA always has been a focus on transition metals and spectroscopy as well as a focus on applicability of the implemented methods to “real-life” chemical applications involving systems with a few hundred atoms. In addition to being efficient, user friendly, and, to the largest extent possible, platform independent, ORCA features a number of methods that are either unique to ORCA or have been first implemented in the course of the ORCA development. Next to a range of spectroscopic and magnetic properties, the linear- or low-order single- and multi-reference local correlation methods based on pair natural orbitals (domain based local pair natural orbital methods) should be mentioned here. Consequently, ORCA is a widely used program in various areas of chemistry and spectroscopy with a current user base of over 22 000 registered users in academic research and in industry.},
  file = {/Users/rgoswami/Zotero default/storage/AKL9GKVH/Neese et al_2020_The ORCA quantum chemistry program package.pdf}
}

@article{neeseORCAQuantumChemistry2020a,
  title = {The {{ORCA}} Quantum Chemistry Program Package},
  author = {Neese, Frank and Wennmohs, Frank and Becker, Ute and Riplinger, Christoph},
  date = {2020-06-12},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {152},
  number = {22},
  pages = {224108},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/5.0004608},
  url = {https://aip.scitation.org/doi/full/10.1063/5.0004608},
  urldate = {2021-06-07},
  abstract = {In this contribution to the special software-centered issue, the ORCA program package is described. We start with a short historical perspective of how the project began and go on to discuss its current feature set. ORCA has grown into a rather comprehensive general-purpose package for theoretical research in all areas of chemistry and many neighboring disciplines such as materials sciences and biochemistry. ORCA features density functional theory, a range of wavefunction based correlation methods, semi-empirical methods, and even force-field methods. A range of solvation and embedding models is featured as well as a complete intrinsic to ORCA quantum mechanics/molecular mechanics engine. A specialty of ORCA always has been a focus on transition metals and spectroscopy as well as a focus on applicability of the implemented methods to “real-life” chemical applications involving systems with a few hundred atoms. In addition to being efficient, user friendly, and, to the largest extent possible, platform independent, ORCA features a number of methods that are either unique to ORCA or have been first implemented in the course of the ORCA development. Next to a range of spectroscopic and magnetic properties, the linear- or low-order single- and multi-reference local correlation methods based on pair natural orbitals (domain based local pair natural orbital methods) should be mentioned here. Consequently, ORCA is a widely used program in various areas of chemistry and spectroscopy with a current user base of over 22 000 registered users in academic research and in industry.},
  file = {/Users/rgoswami/Zotero default/storage/KTZK24C9/Neese et al_2020_The ORCA quantum chemistry program package.pdf;/Users/rgoswami/Zotero default/storage/MZVGGKFI/5.html}
}

@article{oboyleCclibLibraryPackageindependent2008a,
  title = {Cclib: {{A}} Library for Package-Independent Computational Chemistry Algorithms},
  shorttitle = {Cclib},
  author = {O'boyle, Noel M. and Tenderholt, Adam L. and Langner, Karol M.},
  date = {2008},
  journaltitle = {Journal of Computational Chemistry},
  volume = {29},
  number = {5},
  pages = {839--845},
  issn = {1096-987X},
  doi = {10.1002/jcc.20823},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.20823},
  urldate = {2022-06-28},
  abstract = {There are now a wide variety of packages for electronic structure calculations, each of which differs in the algorithms implemented and the output format. Many computational chemistry algorithms are only available to users of a particular package despite being generally applicable to the results of calculations by any package. Here we present cclib, a platform for the development of package-independent computational chemistry algorithms. Files from several versions of multiple electronic structure packages are automatically detected, parsed, and the extracted information converted to a standard internal representation. A number of population analysis algorithms have been implemented as a proof of principle. In addition, cclib is currently used as an input filter for two GUI applications that analyze output files: PyMOlyze and GaussSum. © 2007 Wiley Periodicals, Inc. J Comput Chem, 2008},
  langid = {english},
  keywords = {algorithms,computational chemistry,Python},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.20823},
  file = {/Users/rgoswami/Zotero default/storage/5JWTTYX8/O'boyle et al_2008_cclib.pdf}
}

@article{oliphantPythonScientificComputing2007,
  title = {Python for {{Scientific Computing}}},
  author = {Oliphant, T. E.},
  date = {2007-05},
  journaltitle = {Computing in Science Engineering},
  volume = {9},
  number = {3},
  pages = {10--20},
  issn = {1521-9615},
  doi = {10/fjzzc8},
  abstract = {Python is an excellent "steering" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},
  keywords = {Application software,computer languages,Embedded software,high level languages,High level languages,high-level language,Internet,Libraries,Prototypes,Python,scientific codes,scientific computing,Scientific computing,scientific programming,Software standards,Standards development,steering language,Writing},
  annotation = {02159},
  file = {/Users/rgoswami/Zotero default/storage/MDDUXG8W/dgoswamiFemtoLab-Oliphant_2007_Python_for_Scientific_Computing.pdf;/Users/rgoswami/Zotero default/storage/NP97FKQ7/dgoswamiFemtoLab-Oliphant_2007_Python_for_Scientific_Computing.pdf;/Users/rgoswami/Zotero default/storage/44U4UY4S/4160250.html}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12-02},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  issn = {0036-8075, 1095-9203},
  doi = {10/fdv356},
  url = {https://science.sciencemag.org/content/334/6060/1226},
  urldate = {2019-09-04},
  abstract = {{$<$}p{$>$}Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.{$<$}/p{$>$}},
  langid = {english},
  annotation = {00860},
  file = {/Users/rgoswami/Zotero default/storage/7E2HYDD6/dgoswamiFemtoLab-Peng_2011_Reproducible_Research_in_Computational_Science.pdf;/Users/rgoswami/Zotero default/storage/LZDJHH2Y/tab-pdf.html}
}

@article{pizziAiiDAAutomatedInteractive2016,
  title = {{{AiiDA}}: Automated Interactive Infrastructure and Database for Computational Science},
  shorttitle = {{{AiiDA}}},
  author = {Pizzi, Giovanni and Cepellotti, Andrea and Sabatini, Riccardo and Marzari, Nicola and Kozinsky, Boris},
  date = {2016-01-01},
  journaltitle = {Computational Materials Science},
  shortjournal = {Computational Materials Science},
  volume = {111},
  pages = {218--230},
  issn = {0927-0256},
  doi = {10.1016/j.commatsci.2015.09.013},
  url = {http://www.sciencedirect.com/science/article/pii/S0927025615005820},
  urldate = {2020-07-07},
  abstract = {Computational science has seen in the last decades a spectacular rise in the scope, breadth, and depth of its efforts. Notwithstanding this prevalence and impact, it is often still performed using the renaissance model of individual artisans gathered in a workshop, under the guidance of an established practitioner. Great benefits could follow instead from adopting concepts and tools coming from computer science to manage, preserve, and share these computational efforts. We illustrate here our paradigm sustaining such vision, based around the four pillars of Automation, Data, Environment, and Sharing. We then discuss its implementation in the open-source AiiDA platform (http://www.aiida.net), that has been tuned first to the demands of computational materials science. AiiDA’s design is based on directed acyclic graphs to track the provenance of data and calculations, and ensure preservation and searchability. Remote computational resources are managed transparently, and automation is coupled with data storage to ensure reproducibility. Last, complex sequences of calculations can be encoded into scientific workflows. We believe that AiiDA’s design and its sharing capabilities will encourage the creation of social ecosystems to disseminate codes, data, and scientific workflows.},
  langid = {english},
  keywords = {Directed acyclic graph,High-throughput,Materials database,Provenance,Reproducibility,Scientific workflow},
  file = {/Users/rgoswami/Zotero default/storage/RE7MJLGB/Pizzi et al_2016_AiiDA.pdf;/Users/rgoswami/Zotero default/storage/SXMUL9AI/S0927025615005820.html}
}

@unpublished{rahamanSpectralBiasNeural2019,
  title = {On the {{Spectral Bias}} of {{Neural Networks}}},
  author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred A. and Bengio, Yoshua and Courville, Aaron},
  date = {2019-05-31},
  eprint = {1806.08734},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1806.08734},
  urldate = {2020-03-18},
  abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random inputoutput mappings with 100\% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we highlight a learning bias of deep networks towards low frequency functions – i.e. functions that vary globally without local fluctuations – which manifests itself as a frequency-dependent learning speed. Intuitively, this property is in line with the observation that over-parameterized networks prioritize learning simple patterns that generalize across data samples. We also investigate the role of the shape of the data manifold by presenting empirical and theoretical evidence that, somewhat counter-intuitively, learning higher frequencies gets easier with increasing manifold complexity.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/rgoswami/Zotero default/storage/E43VTRZA/Rahaman et al. - 2019 - On the Spectral Bias of Neural Networks.pdf}
}

@article{sandveTenSimpleRules2013,
  title = {Ten {{Simple Rules}} for {{Reproducible Computational Research}}},
  author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
  date = {2013-10-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {9},
  number = {10},
  pages = {e1003285},
  issn = {1553-7358},
  doi = {10/pjb},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
  urldate = {2019-09-04},
  langid = {english},
  keywords = {Archives,Computer and information sciences,Computer applications,Habits,Replication studies,Reproducibility,Sequence analysis,Source code},
  annotation = {00398},
  file = {/Users/rgoswami/Zotero default/storage/EAN42865/dgoswamiFemtoLab-Sandve_et_al_2013_Ten_Simple_Rules_for_Reproducible_Computational_Research.pdf;/Users/rgoswami/Zotero default/storage/F2HQFHFK/article.html}
}

@article{schaeferMethyleneParadigmComputational1986,
  title = {Methylene: {{A Paradigm}} for {{Computational Quantum Chemistry}}},
  shorttitle = {Methylene},
  author = {Schaefer, Henry F.},
  date = {1986-03-07},
  journaltitle = {Science},
  volume = {231},
  number = {4742},
  eprint = {17818539; http://web.archive.org/web/20200929150418/https://science.sciencemag.org/content/231/4742/1100},
  eprinttype = {pmid},
  pages = {1100--1107},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.231.4742.1100},
  url = {10.1126/science.231.4742.1100},
  urldate = {2020-09-29},
  abstract = {The year 1970 has been suggested as a starting date for the "third age of quantum chemistry," in which theory takes on not only qualitative but also quantitative value. In fact, each of the years 1960, 1970, 1972, and 1977 is of historical value in the unraveling of the structure and energetics of the CH2 molecule, methylene. What took place for methylene, namely the establishment of credibility for theory, has subsequently taken place for many other molecules. Three important roles for quantitative theory are outlined: (i) theory precedes experiment; (ii) theory overturns experiment, as resolved by later experiments; and (iii) theory and experiment work together to gain insight that is afforded independently to neither. Several examples from each of the three classes are given.},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/MISJIGCA/SchaeferScience86.pdf;/Users/rgoswami/Zotero default/storage/PEZZP74Z/1100.html}
}

@article{schuttUnifyingMachineLearning2019,
  title = {Unifying Machine Learning and Quantum Chemistry with a Deep Neural Network for Molecular Wavefunctions},
  author = {Schütt, K. T. and Gastegger, M. and Tkatchenko, A. and Müller, K.-R. and Maurer, R. J.},
  date = {2019-11-15},
  journaltitle = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5024},
  publisher = {{Nature Publishing Group; http://web.archive.org/web/20200928122955/https://www.nature.com/articles/s41467-019-12875-2}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12875-2},
  url = {10.1038/s41467-019-12875-2},
  urldate = {2020-09-28},
  abstract = {Machine learning advances chemistry and materials science by enabling large-scale exploration of chemical space based on quantum chemical calculations. While these models supply fast and accurate predictions of atomistic chemical properties, they do not explicitly capture the electronic degrees of freedom of a molecule, which limits their applicability for reactive chemistry and chemical analysis. Here we present a deep learning framework for the prediction of the quantum mechanical wavefunction in a local basis of atomic orbitals from which all other ground-state properties can be derived. This approach retains full access to the electronic structure via the wavefunction at force-field-like efficiency and captures quantum mechanics in an analytically differentiable representation. On several examples, we demonstrate that this opens promising avenues to perform inverse design of molecular structures for targeting electronic property optimisation and a clear path towards increased synergy of machine learning and quantum chemistry.},
  issue = {1},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/UWFV2VN6/Schütt et al_2019_Unifying machine learning and quantum chemistry with a deep neural network for.pdf;/Users/rgoswami/Zotero default/storage/IKNSEYLF/s41467-019-12875-2.html}
}

@article{seniorProteinStructurePrediction2019,
  title = {Protein Structure Prediction Using Multiple Deep Neural Networks in the 13th {{Critical Assessment}} of {{Protein Structure Prediction}} ({{CASP13}})},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and Žídek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  date = {2019},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  volume = {87},
  number = {12},
  pages = {1141--1148},
  issn = {1097-0134},
  doi = {10.1002/prot.25834},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.25834},
  urldate = {2020-04-05},
  abstract = {We describe AlphaFold, the protein structure prediction system that was entered by the group A7D in CASP13. Submissions were made by three free-modeling (FM) methods which combine the predictions of three neural networks. All three systems were guided by predictions of distances between pairs of residues produced by a neural network. Two systems assembled fragments produced by a generative neural network, one using scores from a network trained to regress GDT\_TS. The third system shows that simple gradient descent on a properly constructed potential is able to perform on par with more expensive traditional search techniques and without requiring domain segmentation. In the CASP13 FM assessors' ranking by summed z-scores, this system scored highest with 68.3 vs 48.2 for the next closest group (an average GDT\_TS of 61.4). The system produced high-accuracy structures (with GDT\_TS scores of 70 or higher) for 11 out of 43 FM domains. Despite not explicitly using template information, the results in the template category were comparable to the best performing template-based methods.},
  langid = {english},
  keywords = {CASP,deep learning,machine learning,protein structure prediction},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/prot.25834},
  file = {/Users/rgoswami/Zotero default/storage/4W5EH7VN/senior2019.pdf;/Users/rgoswami/Zotero default/storage/DL5ADRKM/Senior et al. - 2019 - Protein structure prediction using multiple deep n.pdf;/Users/rgoswami/Zotero default/storage/LWWZWUZQ/prot.html}
}

@article{smithMolSSIQCArchiveProject2021,
  title = {The {{MolSSI QCArchive}} Project: {{An}} Open-Source Platform to Compute, Organize, and Share Quantum Chemistry Data},
  shorttitle = {The {{MolSSI QCArchive}} Project},
  author = {Smith, Daniel G. A. and Altarawy, Doaa and Burns, Lori A. and Welborn, Matthew and Naden, Levi N. and Ward, Logan and Ellis, Sam and Pritchard, Benjamin P. and Crawford, T. Daniel},
  date = {2021},
  journaltitle = {WIREs Computational Molecular Science},
  volume = {11},
  number = {2},
  pages = {e1491},
  issn = {1759-0884},
  doi = {10.1002/wcms.1491},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1491},
  urldate = {2022-06-28},
  abstract = {The Molecular Sciences Software Institute's (MolSSI) Quantum Chemistry Archive (QCArchive) project is an umbrella name that covers both a central server hosted by MolSSI for community data and the Python-based software infrastructure that powers automated computation and storage of quantum chemistry (QC) results. The MolSSI-hosted central server provides the computational molecular sciences community a location to freely access tens of millions of QC computations for machine learning, methodology assessment, force-field fitting, and more through a Python interface. Facile, user-friendly mining of the centrally archived quantum chemical data also can be achieved through web applications found at https://qcarchive.molssi.org. The software infrastructure can be used as a standalone platform to compute, structure, and distribute hundreds of millions of QC computations for individuals or groups of researchers at any scale. The QCArchive Infrastructure is open-source (BSD-3C), code repositories can be found at https://github.com/MolSSI, and releases can be downloaded via PyPI and Conda. This article is categorized under: Electronic Structure Theory {$>$} Ab Initio Electronic Structure Methods Software {$>$} Quantum Chemistry Data Science {$>$} Computer Algorithms and Programming},
  langid = {english},
  keywords = {databases,density functional theory,high-throughput computing,machine learning,quantum chemistry.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.1491},
  file = {/Users/rgoswami/Zotero default/storage/C4IMADBE/Smith et al. - 2021 - The MolSSI QCArchive project An open-source platf.pdf;/Users/rgoswami/Zotero default/storage/GQXXMSFE/Smith et al_2021_The MolSSI QCArchive project.pdf;/Users/rgoswami/Zotero default/storage/M4YGBVW5/wcms.html}
}

@article{virtanenSciPyFundamentalAlgorithms2020,
  title = {{{SciPy}} 1.0: Fundamental Algorithms for Scientific Computing in {{Python}}},
  shorttitle = {{{SciPy}} 1.0},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
  options = {useprefix=true},
  date = {2020-03},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {17},
  number = {3},
  pages = {261--272},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-019-0686-2},
  url = {https://www.nature.com/articles/s41592-019-0686-2},
  urldate = {2021-07-13},
  abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
  issue = {3},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Biophysical chemistry;Computational biology and bioinformatics;Technology Subject\_term\_id: biophysical-chemistry;computational-biology-and-bioinformatics;technology},
  file = {/Users/rgoswami/Zotero default/storage/ALCDCLTN/10.1038@s41592-019-0686-2.pdf#view=FitH.pdf;/Users/rgoswami/Zotero default/storage/NT34XPMA/Virtanen et al_2020_SciPy 1.pdf;/Users/rgoswami/Zotero default/storage/KPZBUBZS/s41592-019-0686-2.html}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the {{Tidyverse}}},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  date = {2019-11-21},
  journaltitle = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  issn = {2475-9066},
  doi = {10.21105/joss.01686},
  url = {10.21105/joss.01686},
  urldate = {2020-11-28},
  abstract = {Wickham et al., (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686},
  langid = {english},
  file = {/Users/rgoswami/Zotero default/storage/DF7E33VK/Wickham et al_2019_Welcome to the Tidyverse.pdf}
}

@book{wilkinsonGrammarGraphics2005,
  title = {The Grammar of Graphics},
  author = {Wilkinson, Leland and Wills, Graham},
  date = {2005},
  series = {Statistics and Computing},
  edition = {2nd ed},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-24544-7},
  pagetotal = {690},
  keywords = {Graphic methods Data processing,Statistics}
}


