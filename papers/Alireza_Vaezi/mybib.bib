# Feel free to delete these first few references, which are specific to the template:

@article{Hansen2021-fd,
  title   = {{CiliaQ}: a simple, open-source software for automated quantification of ciliary morphology and fluorescence in 2D, 3D, and {4D} images},
  author  = {Hansen, Jan Niklas and Rassmann, Sebastian and St{\"u}ven, Birthe and Jurisch-Yaksi, Nathalie and Wachten, Dagmar},
  journal = {The European Physical Journal E},
  volume  = 44,
  number  = 2,
  pages   = {18},
  month   = mar,
  year    = 2021,
  doi     = {https://doi.org/10.1140/epje/s10189-021-00031-y}
}

@article{lee2011muco,
  title     = {Muco-ciliary transport: effect of mucus viscosity, cilia beat frequency and cilia density},
  author    = {Lee, WL and Jayathilake, PG and Tan, Zhijun and Le, DV and Lee, HP and Khoo, BC},
  journal   = {Computers {&} Fluids},
  volume    = {49},
  number    = {1},
  pages     = {214--221},
  year      = {2011},
  publisher = {Elsevier},
  doi       = {https://doi.org/10.1016/j.compfluid.2011.05.016}
}


@article{doretto2003dynamic,
  title     = {Dynamic textures},
  author    = {Doretto, Gianfranco and Chiuso, Alessandro and Wu, Ying Nian and Soatto, Stefano},
  journal   = {International journal of computer vision},
  volume    = {51},
  pages     = {91--109},
  year      = {2003},
  publisher = {Springer},
  doi       = {https://doi.org/10.1023/A:1021669406132}
}



@inproceedings{Hyndman2007HigherorderAM,
  title     = {Higher-order Autoregressive Models for Dynamic Textures},
  author    = {Midori Hyndman and Allan D. Jepson and David J. Fleet},
  booktitle = {British Machine Vision Conference},
  year      = {2007},
  url       = {https://api.semanticscholar.org/CorpusID:15060494},
  doi       = {http://dx.doi.org/10.5244/C.21.76}
}

@misc{Iakubovskii:2019,
  author       = {Pavel Iakubovskii},
  title        = {Segmentation Models Pytorch},
  year         = {2019},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/qubvel/segmentation_models.pytorch}}
}


@inproceedings{kirillov2017unified,
  title        = {A unified architecture for instance and semantic segmentation},
  author       = {Kirillov, Alexander and He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle    = {Computer Vision and Pattern Recognition Conference},
  year         = {2017},
  organization = {CVPR},
  doi          = {https://doi.org/10.48550/arXiv.2112.04603}
}
@inproceedings{vaezi2022novel,
  title     = {A Novel Pipeline for Cell Instance Segmentation, Tracking and Motility Classification of Toxoplasma Gondii in 3D Space.},
  author    = {Vaezi, Seyed Alireza and Orlando, Gianni and Fazli, Mojtaba Sedigh and Ward, Gary E and Moreno, Silvia NJ and Quinn, Shannon},
  booktitle = {SciPy},
  pages     = {60--63},
  year      = {2022},
  doi       = {https://doi.org/10.25080/majora-212e5952-009}
}


@inproceedings{zain2022low,
  title     = {Low Level Feature Extraction for Cilia Segmentation},
  author    = {Zain, Meekail and Miller, Eric and Quinn, Shannon and Lo, Cecilia},
  booktitle = {Proceedings of the Python in Science Conference},
  year      = {2022},
  doi       = {https://doi.org/10.25080/majora-212e5952-026}
}

@inproceedings{zain2020towards,
  title     = {Towards an unsupervised spatiotemporal representation of cilia video using a modular generative pipeline},
  author    = {Zain, Meekail and Rao, Sonia and Safir, Nathan and Wyner, Quinn and Humphrey, Isabella and Eldridge, Alex and Li, Chenxiao and AlAila, BahaaEddin and Quinn, Shannon},
  booktitle = {Proceedings of the Python in Science Conference},
  year      = {2020},
  doi       = {http://dx.doi.org/10.25080/Majora-342d178e-017}
}

@article{quinn2015automated,
  title     = {Automated identification of abnormal respiratory ciliary motion in nasal biopsies},
  author    = {Quinn, Shannon P and Zahid, Maliha J and Durkin, John R and Francis, Richard J and Lo, Cecilia W and Chennubhotla, S Chakra},
  journal   = {Science translational medicine},
  volume    = {7},
  number    = {299},
  pages     = {299ra124--299ra124},
  year      = {2015},
  publisher = {American Association for the Advancement of Science},
  doi       = {http://dx.doi.org/10.1126/scitranslmed.aaa1233}
}

@article{YAKIMOVICH2021100383,
  title    = {Labels in a haystack: Approaches beyond supervised learning in biomedical applications},
  journal  = {Patterns},
  volume   = {2},
  number   = {12},
  pages    = {100383},
  year     = {2021},
  issn     = {2666-3899},
  doi      = {https://doi.org/10.1016/j.patter.2021.100383},
  url      = {https://www.sciencedirect.com/science/article/pii/S2666389921002506},
  author   = {Artur Yakimovich and AnaÃ«l Beaugnon and Yi Huang and Elif Ozkirimli},
  keywords = {machine learning, data labeling, data value, active learning, self-supervised learning, semi-supervised learning, data annotation, zero-shot learning},
  abstract = {Summary Recent advances in biomedical machine learning demonstrate great potential for data-driven techniques in health care and biomedical research. However, this potential has thus far been hampered by both the scarcity of annotated data in the biomedical domain and the diversity of the domain's subfields. While unsupervised learning is capable of finding unknown patterns in the data by design, supervised learning requires human annotation to achieve the desired performance through training. With the latter performing vastly better than the former, the need for annotated datasets is high, but they are costly and laborious to obtain. This review explores a family of approaches existing between the supervised and the unsupervised problem setting. The goal of these algorithms is to make more efficient use of the available labeled data. The advantages and limitations of each approach are addressed and perspectives are provided.}
}

@article{van2020survey,
  title     = {A survey on semi-supervised learning},
  author    = {Van Engelen, Jesper E and Hoos, Holger H},
  journal   = {Machine learning},
  volume    = {109},
  number    = {2},
  pages     = {373--440},
  year      = {2020},
  publisher = {Springer},
  doi       = {http://dx.doi.org/10.1007/s10994-019-05855-6}
}
@article{settles2009active,
  title     = {Active learning literature survey},
  author    = {Settles, Burr},
  year      = {2009},
  publisher = {University of Wisconsin-Madison Department of Computer Sciences}
}
@article{10.3389/fcvm.2020.00105,
  author   = {Chen, Chen and Bai, Wenjia and Davies, Rhodri H. and Bhuva, Anish N. and Manisty, Charlotte H. and Augusto, Joao B. and Moon, James C and Aung, Nay and Lee, Aaron M. and Sanghvi, Mihir M. and Fung, Kenneth and Paiva, Jose Miguel and Petersen, Steffen E. and Lukaschuk, Elena and Piechnik, Stefan K. and Neubauer, Stefan and Rueckert, Daniel},
  title    = {Improving the Generalizability of Convolutional Neural Network-Based Segmentation on CMR Images},
  journal  = {Frontiers in Cardiovascular Medicine},
  volume   = {7},
  year     = {2020},
  url      = {https://www.frontiersin.org/articles/10.3389/fcvm.2020.00105},
  doi      = {https://doi.org/10.3389/fcvm.2020.00105},
  issn     = {2297-055X},
  abstract = {Background: Convolutional neural network (CNN) based segmentation methods provide an efficient and automated way for clinicians to assess the structure and function of the heart in cardiac MR images. While CNNs can generally perform the segmentation tasks with high accuracy when training and test images come from the same domain (e.g., same scanner or site), their performance often degrades dramatically on images from different scanners or clinical sites.Methods: We propose a simple yet effective way for improving the network generalization ability by carefully designing data normalization and augmentation strategies to accommodate common scenarios in multi-site, multi-scanner clinical imaging data sets. We demonstrate that a neural network trained on a single-site single-scanner dataset from the UK Biobank can be successfully applied to segmenting cardiac MR images across different sites and different scanners without substantial loss of accuracy. Specifically, the method was trained on a large set of 3,975 subjects from the UK Biobank. It was then directly tested on 600 different subjects from the UK Biobank for intra-domain testing and two other sets for cross-domain testing: the ACDC dataset (100 subjects, 1 site, 2 scanners) and the BSCMR-AS dataset (599 subjects, 6 sites, 9 scanners).Results: The proposed method produces promising segmentation results on the UK Biobank test set which are comparable to previously reported values in the literature, while also performing well on cross-domain test sets, achieving a mean Dice metric of 0.90 for the left ventricle, 0.81 for the myocardium, and 0.82 for the right ventricle on the ACDC dataset; and 0.89 for the left ventricle, 0.83 for the myocardium on the BSCMR-AS dataset.Conclusions: The proposed method offers a potential solution to improve CNN-based model generalizability for the cross-scanner and cross-site cardiac MR image segmentation task.}
}
@article{Krois2021,
  author  = {Krois, Joachim and Garcia Cantu, Anselmo and Chaurasia, Akhilanand and Patil, Ranjitkumar and Chaudhari, Prabhat Kumar and Gaudin, Robert and Gehrung, Sascha and Schwendicke, Falk},
  title   = {Generalizability of deep learning models for dental image analysis},
  journal = {Scientific Reports},
  year    = {2021},
  month   = {Mar},
  day     = {17},
  volume  = {11},
  number  = {1},
  pages   = {6102},
  issn    = {2045-2322},
  doi     = {http://dx.doi.org/10.1038/s41598-021-85454-5},
  url     = {10.1038/s41598-021-85454-5}
}
@article{10.1148/ryai.2020190195,
  author  = {Yan, Wenjun and Huang, Lu and Xia, Liming and Gu, Shengjia and Yan, Fuhua and Wang, Yuanyuan and Tao, Qian},
  title   = {MRI Manufacturer Shift and Adaptation: Increasing the           Generalizability of Deep Learning Segmentation for MR Images Acquired with           Different Scanners},
  journal = {Radiology: Artificial Intelligence},
  volume  = {2},
  number  = {4},
  pages   = {e190195},
  year    = {2020},
  doi     = {10.1148/ryai.2020190195},
  note    = {PMID: 33937833},
  url     = {10.1148/ryai.2020190195},
  eprint  = {10.1148/ryai.2020190195}
}
@article{Sandfort2019,
  author  = {Sandfort, Veit and Yan, Ke and Pickhardt, Perry J. and Summers, Ronald M.},
  title   = {Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks},
  journal = {Scientific Reports},
  year    = {2019},
  month   = {Nov},
  day     = {15},
  volume  = {9},
  number  = {1},
  pages   = {16884},
  issn    = {2045-2322},
  doi     = {https://doi.org/10.1016/j.imu.2021.100779}
}
@article{YAKIMOVICH2021100383,
  title    = {Labels in a haystack: Approaches beyond supervised learning in biomedical applications},
  journal  = {Patterns},
  volume   = {2},
  number   = {12},
  pages    = {100383},
  year     = {2021},
  issn     = {2666-3899},
  doi      = {https://doi.org/10.1016/j.patter.2021.100383},
  url      = {https://www.sciencedirect.com/science/article/pii/S2666389921002506},
  author   = {Artur Yakimovich and AnaÃ«l Beaugnon and Yi Huang and Elif Ozkirimli},
  keywords = {machine learning, data labeling, data value, active learning, self-supervised learning, semi-supervised learning, data annotation, zero-shot learning},
  abstract = {Summary Recent advances in biomedical machine learning demonstrate great potential for data-driven techniques in health care and biomedical research. However, this potential has thus far been hampered by both the scarcity of annotated data in the biomedical domain and the diversity of the domain's subfields. While unsupervised learning is capable of finding unknown patterns in the data by design, supervised learning requires human annotation to achieve the desired performance through training. With the latter performing vastly better than the former, the need for annotated datasets is high, but they are costly and laborious to obtain. This review explores a family of approaches existing between the supervised and the unsupervised problem setting. The goal of these algorithms is to make more efficient use of the available labeled data. The advantages and limitations of each approach are addressed and perspectives are provided.}
}

@article{van2001art,
  title     = {The art of data augmentation},
  author    = {Van Dyk, David A and Meng, Xiao-Li},
  journal   = {Journal of Computational and Graphical Statistics},
  volume    = {10},
  number    = {1},
  pages     = {1--50},
  year      = {2001},
  publisher = {Taylor \& Francis},
  doi       = {http://dx.doi.org/10.1198/10618600152418584}
}

@article{krizhevsky2012imagenet,
  title   = {Imagenet classification with deep convolutional neural networks},
  author  = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal = {Advances in neural information processing systems},
  volume  = {25},
  year    = {2012},
  doi     = {10.1145/3065386}
}
@inproceedings{ronneberger2015u,
  title        = {U-net: Convolutional networks for biomedical image segmentation},
  author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle    = {Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages        = {234--241},
  year         = {2015},
  organization = {Springer},
  doi          = {10.48550/arXiv.1505.04597}
}
@article{goodfellow2014generative,
  title   = {Generative adversarial nets},
  author  = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal = {Advances in neural information processing systems},
  volume  = {27},
  year    = {2014},
  doi     = {10.48550/arXiv.1406.2661}
}
@article{yi2019generative,
  title     = {Generative adversarial network in medical imaging: A review},
  author    = {Yi, Xin and Walia, Ekta and Babyn, Paul},
  journal   = {Medical image analysis},
  volume    = {58},
  pages     = {101552},
  year      = {2019},
  publisher = {Elsevier},
  doi       = {https://doi.org/10.48550/arXiv.1809.07294}
}
@article{Sanford2020-yg,
  title    = {Data Augmentation and Transfer Learning to Improve Generalizability of an Automated Prostate Segmentation Model},
  author   = {Sanford, Thomas H and Zhang, Ling and Harmon, Stephanie A and Sackett, Jonathan and Yang, Dong and Roth, Holger and Xu, Ziyue and Kesani, Deepak and Mehralivand, Sherif and Baroni, Ronaldo H and Barrett, Tristan and Girometti, Rossano and Oto, Aytekin and Purysko, Andrei S and Xu, Sheng and Pinto, Peter A and Xu, Daguang and Wood, Bradford J and Choyke, Peter L and Turkbey, Baris},
  journal  = {AJR Am J Roentgenol},
  volume   = 215,
  number   = 6,
  pages    = {1403--1410},
  month    = oct,
  year     = 2020,
  address  = {United States},
  keywords = {artificial intelligence; prostate MRI; segmentation},
  language = {en},
  doi      = {http://dx.doi.org/10.2214/AJR.19.22347}
}

@inproceedings{NEURIPS2019_eb1e7832,
  author    = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Transfusion: Understanding Transfer Learning for Medical Imaging},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2019/file/eb1e78328c46506b46a4ac4a1e378b91-Paper.pdf},
  volume    = {32},
  year      = {2019},
  doi       = {https://doi.org/10.48550/arXiv.1902.07208}
}

@misc{hutchinson2017overcoming,
  title         = {Overcoming data scarcity with transfer learning},
  author        = {Maxwell L. Hutchinson and Erin Antono and Brenna M. Gibbons and Sean Paradiso and Julia Ling and Bryce Meredig},
  year          = {2017},
  eprint        = {1711.05099},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  doi           = {https://doi.org/10.48550/arXiv.1711.05099}
}
@inproceedings{kim2019self,
  title     = {Self-supervised video representation learning with space-time cubic puzzles},
  author    = {Kim, Dahun and Cho, Donghyeon and Kweon, In So},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume    = {33},
  number    = {01},
  pages     = {8545--8552},
  year      = {2019},
  doi       = {https://doi.org/10.48550/arXiv.1811.09795}
}

@inproceedings{kolesnikov2019revisiting,
  title     = {Revisiting self-supervised visual representation learning},
  author    = {Kolesnikov, Alexander and Zhai, Xiaohua and Beyer, Lucas},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages     = {1920--1929},
  year      = {2019},
  doi       = {https://doi.org/10.48550/arXiv.1901.09005}
}

@inproceedings{mahendran2019cross,
  title        = {Cross pixel optical-flow similarity for self-supervised learning},
  author       = {Mahendran, Aravindh and Thewlis, James and Vedaldi, Andrea},
  booktitle    = {Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part V 14},
  pages        = {99--116},
  year         = {2019},
  organization = {Springer},
  doi          = {https://doi.org/10.48550/arXiv.1807.05636}
}
@article{li2006one,
  title   = {One-shot learning of object categories},
  author  = {Li, Fei-Fei and Fergus, Rob and Perona, Pietro and others},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell},
  volume  = {28},
  number  = {4},
  pages   = {594--611},
  year    = {2006},
  doi     = {http://dx.doi.org/10.1109/TPAMI.2006.79}
}
@inproceedings{miller2000learning,
  title        = {Learning from one example through shared densities on transforms},
  author       = {Miller, Erik G and Matsakis, Nicholas E and Viola, Paul A},
  booktitle    = {Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)},
  volume       = {1},
  pages        = {464--471},
  year         = {2000},
  organization = {IEEE},
  doi          = {https://doi.org/10.1109/CVPR.2000.855856}
}
@article{khatibi2021proposing,
  title     = {Proposing a novel unsupervised stack ensemble of deep and conventional image segmentation (SEDCIS) method for localizing vitiligo lesions in skin images},
  author    = {Khatibi, Toktam and Rezaei, Niloofar and Ataei Fashtami, Leila and Totonchi, Mehdi},
  journal   = {Skin Research and Technology},
  volume    = {27},
  number    = {2},
  pages     = {126--137},
  year      = {2021},
  publisher = {Wiley Online Library},
  doi       = {http://dx.doi.org/10.1111/srt.12920}
}

@inbook{Hoyer-Fender2013,
  author    = {Hoyer-Fender, Sigrid},
  editor    = {Tucker, Kerry L.  and Caspary, Tamara},
  title     = {Primary and Motile Cilia: Their Ultrastructure and Ciliogenesis},
  booktitle = {Cilia and Nervous System Development and Function},
  year      = {2013},
  publisher = {Springer Netherlands},
  address   = {Dordrecht},
  pages     = {1--53},
  isbn      = {978-94-007-5808-7},
  doi       = {10.1007/978-94-007-5808-7_1},
  url       = {https://doi.org/10.1007/978-94-007-5808-7_1}
}


@article{lu2018stacked,
  title   = {Stacked Neural Networks for end-to-end ciliary motion analysis},
  author  = {Lu, Charles and Marx, Maurice and Zahid, Maliha and Lo, Cecilia W and Chennubhotla, Chakra and Quinn, Shannon P},
  journal = {arXiv preprint arXiv:1803.07534},
  year    = {2018},
  doi     = {https://doi.org/10.48550/arXiv.1803.07534}
}

@article{https://doi.org/10.1002/ppul.24078,
  author   = {Kempeneers, CÃ©line and Chilvers, Mark A.},
  title    = {To beat, or not to beat, that is question! The spectrum of ciliopathies},
  journal  = {Pediatric Pulmonology},
  volume   = {53},
  number   = {8},
  pages    = {1122-1129},
  keywords = {cilia, ciliopathie, motile cilia, non-motile cilia, primary ciliary dyskinesia, respiratory cilia},
  doi      = {https://doi.org/10.1002/ppul.24078},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ppul.24078},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ppul.24078},
  year     = {2018}
}

